<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="记录学习过程">
<meta property="og:type" content="website">
<meta property="og:title" content="Linuzb&#39;s blog">
<meta property="og:url" content="https://levizebulon.github.io/index.html">
<meta property="og:site_name" content="Linuzb&#39;s blog">
<meta property="og:description" content="记录学习过程">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Linuzb">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://levizebulon.github.io/"/>





  <title>Linuzb's blog</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Linuzb's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/06/13/meshCNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/06/13/meshCNN/" itemprop="url">meshCNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-06-13T21:06:46+08:00">
                2020-06-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MeshCNN-A-Network-with-an-Edge-基于边的卷积网络"><a href="#MeshCNN-A-Network-with-an-Edge-基于边的卷积网络" class="headerlink" title="MeshCNN: A Network with an Edge 基于边的卷积网络"></a>MeshCNN: A Network with an Edge 基于边的卷积网络</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>多边形网格可有效表示3D形状。它们可以精确捕获形状表面和拓扑，并利用不均匀性来表示较大的平坦区域以及尖锐，复杂的特征。但是，这种不均匀性和不规则性限制了使用结合了卷积和合并操作的神经网络进行网格分析的努力。在本文中，我们利用MeshCNN（专门为三角网格设计的卷积神经网络）直接利用网格的独特属性来分析3D形状。与经典的CNN相似，MeshCNN通过利用其固有的测地线连接，将在网格边缘上运行的特殊卷积和池化层相结合。在边缘及其入射三角形的四个边缘上应用卷积，并通过保留表面拓扑的边缘折叠操作应用合并，从而为后续的卷积生成新的网格连接。 MeshCNN了解哪些边会塌陷，从而形成任务驱动的过程，网络将在其中暴露和扩展重要功能，同时丢弃冗余功能。我们展示了任务驱动型池在应用于3D网格的各种学习任务上的有效性</p>
<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><p>三维形状是计算机图形学领域的前沿和中心，也是相关领域（如计算机视觉和计算几何学）的主要商品。 我们周围的形状，尤其是描述自然实体的形状，通常由连续的表面组成。</p>
<p>由于计算的原因，并且为了促进数据处理，已经提出了3D形状的各种离散近似，并被用来表示一系列应用中的形状。 最喜欢的一种是多边形网格表示（或简称为网格），它通过3D空间中的一组2D多边形来近似曲面[Botsch等。 2010]。 网格提供了有效，不均匀的形状表示。 一方面，只需要少量的多边形即可捕获大而简单的表面。 另一方面，表示灵活性可在需要时支持更高的分辨率，从而可以忠实地重建或描绘通常在几何上复杂的显着形状特征。 网格的另一个有利可图的特性是其固有的连通性信息。 这形成了底层表面的全面表示。</p>
<p>与另一个流行的选择：点云表示相比，这些优势显而易见。 尽管它简单易行，并且与常见的数据采集技术（扫描）直接相关，但是当需要更高的质量和尖锐形状特征的保留时，点云表示就不够用了</p>
<p>近年来，在图像上使用卷积神经网络（CNN）已显示出在各种任务（例如分类和语义分割）上的出色表现[2013; 2014; 2018]。 他们成功的秘诀在于卷积，非线性和池化层的组合，从而形成了一个框架，该框架对于输入的无关变化是不变的（或稳健的）[LeCun 2012; 克里热夫斯基等。 2012]。 但是，由于图像是在离散值的规则网格上表示的，因此扩展CNN以在不规则结构上工作并不容易。</p>
<p>最初的方法通过使用常规表示来绕开CNN适应不规则数据的方法：将3D形状映射到多个2D投影[Su等。 2015]或3D体素网格[Wu等。 2015]。 虽然这些方法得益于直接使用众所周知的图像CNN运算符，但它们的间接表示需要具有浪费或冗余的CNN计算（例如，在未占用的体素上的卷积）的大量内存。</p>
<p>更有效的方法将CNN直接应用于无规则和稀疏点云表示[Qi等。 2017a]。 尽管这些方法得益于紧凑的输入表示形式，但它们本质上是不考虑局部表面的。 此外，邻居和连通性的概念定义不清，使得卷积和池化操作的应用变得不那么重要。 这种模棱两可的结果导致了一系列针对克服这一挑战的工作[Monti等。 2017; Wang等。 2018a; Li等。 2018; Yi等。 2017]</p>
<p>为了挖掘本地网格表示的自然潜力，我们提出了MeshCNN：类似于众所周知的CNN的神经网络，但专门为网格设计。 MeshCNN直接在不规则的三角形网格上运行，执行与独特的网格属性协调设计的卷积和合并操作。 在MeshCNN中，网格的边缘类似于图像中的像素，因为它们是应用所有操作的基本构件。 我们选择使用边，因为每个边都恰好入射到两个面（三角形）上，这定义了四个边的自然固定大小的卷积邻域（请参见图2）。 我们利用一致的人脸法线顺序应用对称卷积运算，该运算可了解旋转，缩放和平移变换不变的边缘特征。</p>
<p>MeshCNN的关键功能是独特的池化操作，即网格池，它在不规则结构上运行并在空间上适应任务。 在CNN中，对网络中的要素数量进行下采样合并，从而学习消除信息量较少的特征。由于特征在边缘，因此下采样的直观方法是使用众所周知的网格简化技术边缘折叠[Hoppe 1997 ]。 但是，与传统的边折叠不同，后者消除了引入最小几何失真的边，网格合并将选择要折叠的边以特定于任务的方式委托给网络。 清除的边缘是其特征对使用的物镜贡献最小的边缘（请参见图1和8中的示例）</p>
<p>为了增加灵活性并支持各种可用数据，每个池化层将网格简化为预定的恒定边数。 而且，尽管它产生任何规定的输出边沿计数，但MeshCNN并不知道输入网格的大小，并且能够处理不同的三角剖分。 如图1所示，我们表明中间计算池化步骤以及最终输出在语义上是可以解释的。 为了说明我们方法的适用性，我们在形状分类和分割任务上进行了各种实验，并在通用数据集和高度非均匀网格上向最新方法展示了更好的结果。</p>
<p>为了增加灵活性并支持各种可用数据，每个池化层将网格简化为预定的恒定边数。 而且，尽管它产生任何规定的输出边沿计数，但MeshCNN并不知道输入网格的大小，并且能够处理不同的三角剖分。 如图1所示，我们表明中间计算池化步骤以及最终输出在语义上是可以解释的。 为了说明我们方法的适用性，我们在形状分类和分割任务上进行了各种实验，并在通用数据集和高度非均匀网格上向最新方法展示了更好的结果。</p>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><p>我们介绍或在工作中使用的许多运算符都是基于经典的网格处理技术[Hoppe 1999; Rusinkiewicz和Levoy 2000； Botsch等。 2010; Kalogerakis等。 2010]，或更具体地说，是网格简化技术[Hoppe等。 1993年； Gar Land和Heckbert 1997； Hoppe 1997]。 特别是，我们将边缘折叠技术[Hoppe 1997]用于我们的任务驱动的合并运算符。 传统的网格简化技术旨在以最小的几何变形减少网格元素的数量[Tarini等。 2010; 高等。 2017]，在这项工作中，我们使用网格简化技术来降低神经网络环境下特征图的分辨率。 接下来，我们将根据输入表示类型重新组织有关使用神经网络进行3D数据分析的相关工作。</p>
<p><strong>多视图2D投影</strong> 通过从各种角度通过3D形状的2D投影表示3D形状，可以充分利用2D域中的现有技术和体系结构。 这些渲染图像集用作标准CNN模型的后续处理的输入。 Su等。 [2015]是第一个将多视图CNN应用于形状分类的任务，但是这种方法（按原样）无法执行语义分割。 后来，[Kalogerakis等。 [2017]提出了一个更全面的多视图形状分割框架：为每个视图生成图像级分割图，然后使用CRF（端到端训练）解决标签一致性。 Qi等。 [2016]探索了基于视图的方法和基于体积的方法，并观察了第一种方法与当时可用方法的优越性。</p>
<p><strong>体积</strong> 将3D形状转换为二进制体素形式可以提供类似于图像的2D网格的基于网格的表示。 这样，可以以简单的方式将应用于2D网格的操作扩展到3D网格，从而降低了基于常见图像的方法向形状域的自然转移。 Wu等。 [2015]率先提出了这一概念，并提出了一种处理体素化形状以进行分类和完成的CNN。 随后，布洛克等。 [2016]使用基于体素的变分自动编码器解决了形状重构问题，[Tchapmi等人。 [2017年]将三线性插值和条件随机场（CRF）与体积网络相结合，以促进语义形状分割。 Hanocka等。 [2018]使用体积形状表示来训练网络以回归基于网格的扭曲字段以进行形状对齐，并将估计的变形应用于原始网格。</p>
<p>尽管它们具有诱人的简单性，但其体积表示仍需要大量计算，这需要占用大量内存。 为了缓解这种情况，已经提出了几种加速策略，其中利用空间中形状占用的稀疏性来减少表示[Li等。 2016; Riegler等。 2017; Wang等。 2017; Graham等。 2017]</p>
<p><strong>图</strong>。图结构是允许不规则性的基于网格的表示形式的常见概括。为了支持基于图的数据分析，相当大的注意力已集中到将神经网络应用到涉及以图形式表示的数据的流行任务上，这些数据主要是社交网络，通信中的传感器网络或遗传数据。一种方法主张处理图形表示的拉普拉斯算子[Bruna等。 2014; Henaff等。 2015; Defferrard等。 2016; Kostrikov等。 2018]，因此在频谱领域内运作。另一种方法是通过提取局部连接的区域并将其转换为要由神经网络处理的规范形式来直接处理图形[Niepert等。 2016]。 Atwood等。 [2016]提出了扩散卷积，其中在每个节点上应用扩散来确定其局部邻域。 Monti等。 [2017]使用图空间域将表面参数化为局部斑块。徐等。 [2017]使用表面补丁上的定向卷积来完成语义分割任务。 Yi等。 [2017]在3D分割任务中在频谱域中使用图卷积。 Kostrikov等。 [2018]使用拉普拉斯曲面网络开发了3D形状的生成模型。这样的等。 [2017]引入了图上顶点过滤的概念，但没有合并用于特征聚合的池化操作。这些方法通常在图形的顶点上运行。</p>
<p><strong>Manifold</strong>。 Masci等人的开拓性工作。 [2015]引入了对网格局部特征的深度学习（内部网格描述符类似于[Kokkinos et al。2012]中的描述），并展示了如何使用这些学习的特征进行对应和检索。 具体来说，他们演示了如何使卷积运算成为网格固有的。</p>
<p>通常，流形上的局部斑块近似于欧几里得。 通过将3D歧管参数化为2D，可以使用标准CNN将此特征用于歧管形状分析[Henaff等。 2015; Boscaini等。 2016; Sinha等。 2016; Maron等。 2017; Ezuz等。 2017]。 Boscaini等。 [2015]使用顶点频率分析来学习局部固有3D形状描述符。 另一种方法是使用复曲面拓扑在形状图上定义卷积[Haim等。 2018; Maron等。 2017]。 Poulenard等。 [2018]定义了一个新的卷积层，允许在整个网络层中传播测地信息。</p>
<p>Verma等。 [2018]提出了一种图神经网络，其中卷积运算的每个顶点的邻域不是预先定义的，而是根据其特征动态计算的。 Tatarchenko等。 [2018]引入了切线卷积，其中每个点周围的一个小邻域用于重构应用卷积的局部函数。 与以前的作品不同，他们通过在常规3D网格上进行二次采样来合并池化操作。 还提出了一些生成模型。 Litany等 等 [2018]引入了执行形状完成的自动编码器。 Ranjan等 等 [2018]演示了网格自动编码器如何生成3D面</p>
<p>参见[Bronstein等。 [2017年]，以全面了解地理深度学习。 与以前的方法相比，我们的方法的独特之处在于我们的网络操作是专门为适应网状结构而设计的。 特别是，我们学习了一个独特的池化运算符，它可以根据目标任务选择要简化的区域。</p>
<p>据我们所知，这是第一个提出（i）在网格边缘上进行卷积和（ii）适应于当前任务的学习型网格池化操作的第一项工作。 在[Ranjan et al。 [2018年]，已经提出了针对网格自动编码器的固定合并操作。 在图神经网络的背景下，已经提出了学习的池化操作[Ying等。 2018; Cangea等。 2018]。 但是，这些操作没有考虑到独特的三角形网格属性。</p>
<p>利用双图卷积模型提出了一种提取边缘特征的卷积[Monti et al。 2018]扩展了图关注网络[Velickovic等。 2018]。 但是，他们工作中使用的注意力和优化机制与我们的机制大不相同。 在这项工作中，我们定义了网格的运算符，它们利用了它们的独特结构和属性。 这使我们能够定义导致不可变网络特征的对称卷积。</p>
<p>点云。点云表示形式可以说是所有表示形式中最简单的，它为底层3D形状提供了简洁的近似。与数据采集的紧密关系以及从其他表示形式转换的便捷性，使点云成为数据分析的经典候选者。因此，最近的努力集中在开发使用神经网络进行点云形状分析的技术。 PointNet [Qi等。 [2017a]建议使用1x1卷积，然后使用全局最大池进行阶数不变性。在其后续工作中，PointNet ++ [Qi等。 2017b]，对点进行分区以更好地捕获局部结构。 Wang等。 [2018b]考虑到局部点邻域信息，并根据特征空间中的距离，通过点之间的相似度计算来驱动动态更新。尽管大多数基于点的方法都侧重于全局或中级属性，[Guerrero等。 [2018年]提出了一个网络来估计局部形状属性，例如，根据原始点云来估计法线和曲率，而[Williams等人。 [2018]从点云中学习曲面重建的几何先验。 Atzmon等人[2018]通过将点云函数映射到体积函数中，在点云上定义了一种高效的卷积算子。这使得该方法对于点的顺序不变，并且对数据中的某些变形具有鲁棒性。最近，李等人。 [2018]提出了PointCNN，它将卷积的概念从局部网格扩展到了位于其欧几里得邻域上的点的χ卷积。</p>
<p>在这项工作中，与以前的工作不同，我们依靠网格边缘来提供非均匀的测地邻域信息，并具有一致数量的conv-neighbor。 在边缘上执行不变特征计算，同时利用网格抽取技术（例如边缘塌陷）以符合形状几何和拓扑的方式进行</p>
<h2 id="3-概述：在网格上应用CNN"><a href="#3-概述：在网格上应用CNN" class="headerlink" title="3 概述：在网格上应用CNN"></a>3 概述：在网格上应用CNN</h2><p>计算机图形学中最基本，最常用的3D数据表示法是非均匀多边形网格；即，多边形网格。 大的平坦区域使用少量的大多边形，而详细区域使用大量的多边形。 网格明确表示表面的拓扑：忠实地描述复杂的结构，同时消除与附近表面的接近度（见图3）。</p>
<p>实现我们的目标是将CNN范式直接应用到三角网状网格上，需要对CNN的标准构建块（卷积层和池化层）进行类似的定义和实现。 与以离散值的规则网格表示的图像相反，网格分析的主要挑战是其固有的不规则性和不均匀性。 在这项工作中，我们旨在利用这些具有挑战性的独特属性，而不是绕开它们。 因此，我们将网络设计为有意将卷积和池化操作直接应用于网格的构造，并避免转换为规则且统一的表示形式。</p>
<p><strong>不变卷积</strong>。 在我们的设置中，假定所有形状都表示为流形网格，可能带有边界边缘。 这样的假设保证了每个边缘最多与两个面（三角形）相关，因此与两个或四个其他边缘相邻。 面的顶点按逆时针方向排序，从而为每个边的四个相邻点定义了两种可能的排序。 例如，请参见图4，其中e的1环邻居可以按（a，b，c，d）或（c，d，a，b）排序，具体取决于哪个面定义了第一个邻居。 这使卷积接受场模棱两可，阻碍了不变特征的形成</p>
<p>我们采取了两项行动来解决这个问题，并保证我们网络中的相似性转换（旋转，平移和缩放）不变。 首先，我们精心设计一条边的输入描述符，使其仅包含相对于固有的相似变换固有的几何特征。 其次，我们将四个1环边缘聚合为两对具有很大含义的边缘（例如a和c，以及b和d），并通过在每对上应用简单的对称函数（例如，求和来生成新特征） （a，c））。 将卷积应用于新的对称特征，从而消除了任何阶歧义。</p>
<p><strong>输入功能</strong>。 输入边缘特征是每个边缘的5维向量：每个面的二面角，两个内角和两个边缘长度比。 边缘比率在边缘的长度和每个相邻面的垂直（虚线）之间。 我们对两个基于面部的特征（内角和边长比）中的每一个进行排序，从而解决了排序的歧义并保证了不变性。 观察这些特征都是相对的，使它们不变于平移，旋转和均匀缩放</p>
<p><strong>全局排序</strong>。 边缘的全局排序是特定形状的边缘数据（输入要素）进入网络的顺序。 由于在本地邻域内执行卷积，因此该顺序在卷积阶段没有影响。 通过扩展，完全卷积的任务（例如分段）不受其影响。 对于需要全局特征聚合的任务，例如分类，我们遵循Qi等人的建议。 [2017a]在PointNet中，并放置一个连接网络卷积部分和完全连接部分之间的全局平均池化层。 该层使初始排序变得不太频繁，从而保证了变换的不变性。</p>
<p><strong>池化</strong>。 如图2（b）和（c）所示，网格合并是通过边缘折叠过程完成的。 在（b）中，虚线边缘折叠到一个点，然后，四个入射边缘（蓝色）合并为（c）中的两个（蓝色）边缘。 请注意，在此边折叠操作中，五个边被转换为两个边。 运算符由（最小范数）边缘特征确定优先级，从而允许网络选择要简化的网格部分以及保持完整的网格部分。 这将创建一个任务感知过程，网络将学会根据任务确定对象部件的重要性（见图1）。</p>
<p>我们简化性质的一个显着优势是，就池化层的输出尺寸而言，它在到达最终的完全连接层之前就提供了灵活性。 合并还有助于增强初始网格三角剖分的鲁棒性。 尽管它不能为三角剖分提供等方差，但实际上，通过连续折叠边并简化网格，尽管初始镶嵌效果有所不同，但我们仍观察到了相似表示的收敛性</p>
<h2 id="4-方法"><a href="#4-方法" class="headerlink" title="4 方法"></a>4 方法</h2><p>基于网格的（例如，图像）表示方便地在单个矩阵中提供了空间邻居（连通性）和特征。 但是，由于不规则网格不符合此格式，因此我们必须与连接分开定义要素。 我们通过在网格的标准构造中进行工作来完成此任务</p>
<p>网格由对（V，F）定义，其中V = {v1，v2···}是$R^3$中顶点位置的集合，而F定义连通性（三角形网格的顶点三元组）。 给定（V，F），还使用边E（一组顶点对）定义网格连接。</p>
<p>所有网格元素V，F和E都可以与各种特征（例如法线或颜色）关联。 在这项工作中，E还具有一组功能。 边缘特征从一组相似的不变几何特征开始（在图像的情况下相当于RGB值），并且随着它们在网络层中的前进而发展出更高的抽象度。</p>
<p>在我们的设置中，网格为网络提供了两个属性：卷积邻居的连接性和初始几何输入要素。 一旦提取了输入要素，网格顶点就没有任何意义。 边缘折叠操作之后的新顶点位置对分类和分段任务没有影响，并且仅出于可视化目的对其进行计算。</p>
<p>接下来，我们扩展并提供有关网格卷积，网格池化和网格解池操作的详细信息。</p>
<h3 id="4-1-网格卷积"><a href="#4-1-网格卷积" class="headerlink" title="4.1 网格卷积"></a>4.1 网格卷积</h3><p>我们为边缘定义卷积算子，其中使用四个入射邻居定义空间支持（图3）。 回想卷积是核k与邻域之间的点积，因此边缘特征e及其四个相邻边的卷积为：</p>
<p>$$e\cdot k_0 + \sum_{j=1}^{4} k_j \cdot e^j$$</p>
<p>其中e j是e的第j个卷积邻居的特征。 请注意，如图4所示，e的四个邻居，即（e 1，e 2，e 3，e 4）是（a，b，c，d）或（c，d，a，b ），这样每个滤波器值最多可在两个可能的边上进行操作（例如，a或c上的k1）。 为了保证卷积不变性到输入数据的顺序，我们将一组简单的对称函数应用于不明确的对。 这产生了保证是不变的新的卷积邻居集。 在我们的设置中，边e的接受场为</p>
<p>$$(e^1,e^2,e^3,e^4) = (|a-c|, a+c, |b-d|, b+d)$$</p>
<p>这将导致卷积操作，而该操作会忽略网格元素的初始顺序，因此无论如何都会产生相同的输出。 回想一下，可以使用通用矩阵乘法（GEMM）来实现多通道张量与内核的卷积：通过将图像扩展（或展开）为列矩阵（即im2col [Jia 2014]）。 等效地，我们构建一个未包装的矩阵以有效地执行卷积运算。</p>
<p>在实践中，我们可以通过将所有边缘特征聚合到$n_c \times n_e \times 5$个特征张量中来使用高度优化的批处理算子（例如conv2D），其中ne是边缘数，nc是特征通道数，5是 对于边缘和卷积邻居（等式2）。 使用标准GEMM将这个矩阵乘以卷积权重的矩阵。</p>
<p>卷积操作之后，将生成一个新的批量特征张量，其中新的特征数量等于卷积内核的数量（就像在图像中一样）。 请注意，在每个合并阶段之后，新的连通性将为下一个卷积定义新的卷积邻居</p>
<h2 id="4-2-网格池化"><a href="#4-2-网格池化" class="headerlink" title="4.2 网格池化"></a>4.2 网格池化</h2><p>通过确定三个概括了池化概念的核心操作，我们将常规池化扩展到不规则数据：</p>
<ol>
<li><p>定义给定邻接的池化区域</p>
</li>
<li><p>在每个池化区域中合并要素</p>
</li>
<li><p>重新定义合并功能的邻接关系</p>
</li>
</ol>
<p>为了在常规数据（例如图像）上进行合并，固有地隐含了邻接关系，因此，合并区域直接由所选内核大小确定。 由于每个区域中的要素以产生另一个均匀间隔的网格的方式合并（例如，通过avg或max），因此将再次固有地定义新的邻接关系。 解决了上面定义的三个常规池化操作后，很明显，常规池化是广义过程的特殊情况。</p>
<p>网格池化是通用池化的另一种特殊情况，其邻接关系由拓扑决定。 与图像的自然缩小因子不同，例如2×2池化的自然减少因子为4，我们将网格池定义为一系列边缘收缩操作，其中每个这样的边缘收缩将五个边缘转换为两个边缘。 因此，我们可以通过添加一个超参数来控制每个合并运算符之后所需的网格分辨率，该超参数定义了合并网格中目标边的数量。 在运行期间，提取网格邻接信息需要查询不断更新的特殊数据结构（有关详细信息，请参见[Berg et al。2008]）。</p>
<p>我们通过边缘特征的大小对边缘折叠顺序（使用优先级队列）进行优先排序，从而允许网络选择网格的哪些部分与解决任务有关。 这使网络能够非均匀地折叠某些对丢失最不重要的区域。 回想一下，使两个面相邻的边折叠会导致三个边的删除（如图2所示），因为两个面都变成一个边。 每个面包含三个边：最小边和最小边的两个相邻邻居（请参见图2中红色的最小边和蓝色的相邻边）。 通过获取每个特征通道的平均值，可以将每个面中三个边缘的每个特征合并为一个新的边缘特征。</p>
<p>根据边缘特征的强度优先考虑边缘折叠，将其视为L2范数。 如图5所示，这些特征被聚合，其中有两个合并操作，一个用于最小边缘特征e的每个入射三角形，一个合并，从而产生两个新的特征向量（表示为p和q）。 两个三角形的通道索引i中的边缘特征由下式给出</p>
<p>$$p_i = avg(a_i, b_i, e_i), and, q_i=(c_i, d_i, e_i)$$</p>
<p>边缘折叠后，将更新半边缘数据结构以用于后续的边缘折叠。</p>
<p>最后，请注意，并非每个边缘都可以折叠。 在我们的设置中，不允许产生产生非流形面的边缘折叠，因为它违反了四个卷积邻居的假设。 因此，如果一条边在其1环的交点上具有三个顶点，或者如果具有两个边界顶点，则认为该边无效折叠。</p>
<h3 id="4-3-Mesh-Unpooling"><a href="#4-3-Mesh-Unpooling" class="headerlink" title="4.3 Mesh Unpooling"></a>4.3 Mesh Unpooling</h3><p>解池化是池化操作的（部分）逆过程。 池化层降低特征激活的分辨率（编码或压缩信息）的同时，解池层提高特征激活的分辨率（解码或解压缩信息）。 池化操作记录合并操作的历史记录（例如，最大位置），并使用它们来扩展功能激活。 因此，解池化没有可学习的参数，通常将其与卷积结合以恢复池化操作中丢失的原始分辨率。 与卷积相结合有效地使分拆成为可学习的操作。</p>
<p>每个网格解池层都与网格池化层配对，以对网格拓扑和边缘特征进行上采样。 解池层通过在池化之前存储连接性来恢复上采样的拓扑（在网格池化之前）。 请注意，对连接进行上采样是可逆的操作（就像在图像中一样）。 对于非合并边缘特征计算，我们保留一个图，该图存储从原始边缘（合并之前）到新边缘（合并之后）的邻接关系。 每个未合并的边要素然后是合并的边要素的加权组合。 图5展示了平均池化的情况</p>
<h2 id="5-实验"><a href="#5-实验" class="headerlink" title="5 实验"></a>5 实验</h2><p>MeshCNN是将CNN直接应用于三角形网格的一种通用方法，具有许多应用。 使用第4节中描述的MeshCNN的构建块，我们可以构建不同的网络配置来解决不同的任务。 像常规的CNN一样，这些构件提供了即插即用的框架。 为了提高计算效率，在合并操作中，每个合并操作仅汇总一次要素。 在顺序执行边缘排序和折叠的同时，这种放宽允许在GPU上执行特征聚合操作，从而提高了计算效率</p>
<p>在下面的内容中，我们演示了MeshCNN在分类和分割任务上的性能。 附录A中提供了有关所用网络体系结构的详细信息。</p>
<h3 id="5-1-数据处理"><a href="#5-1-数据处理" class="headerlink" title="5.1 数据处理"></a>5.1 数据处理</h3><p>在所有集合中，我们将每个网格简化为大致相同数量的边。 请注意，如前所述，MeshCNN在所有样本中不需要相同数量的边。 但是，类似于CNN中图像的初始大小调整，几何网格抽取有助于降低输入分辨率，并因此降低训练所需的网络容量。 由于分类任务学习的是全局形状描述，因此与分割任务（2250条边缘）相比，我们通常使用较低的分辨率（750条边缘）。</p>
<p><strong>Augmentation</strong>。 存在几种形式的数据扩充，用于为网络生成更多数据样本。 请注意，由于我们的输入要素是相似不变的，因此应用旋转，平移和各向同性缩放（x，y和z相同）不会生成新的输入要素。 但是，我们可以通过在x，y和z的顶点位置应用各向异性缩放来生成新特征，$&lt;S_x，S_y，S_z&gt;$（每个都从正态分布µ = 1和σ= 0.1中随机采样），这将改变 向网络输入特征。 我们还将顶点移动到网格表面上的不同位置。 此外，我们通过执行随机边缘翻转来增强每个对象的细分。 由于灵活的输入分辨率，我们还可以在训练之前折叠少量的随机边缘。</p>
<h3 id="5-2-网格分类"><a href="#5-2-网格分类" class="headerlink" title="5.2 网格分类"></a>5.2 网格分类</h3><p>SHREC。 我们从SHREC数据集中对30个类别进行了分类[Lian等。 2011]，每类有20个范例。 我们遵循[Ezuz et al。 2017]，其中16和10分别是每类的训练样本数，我们在200个时期后停止训练。 由于我们没有[2017]中使用的精确分割，因此我们对3个随机生成的分割16和10组的结果进行了平均。 表1报告了结果。 为了进行比较，我们直接取自[2017]的评估结果，这些评估结果与SG [Bronstein等。 2011]（功能代表袋），SN [Wu等。 2015]（CNN体积），GI [Sinha等。 2016]（固定几何图像上的CNN），最后是GWCNN [2017]（学习过的几何图像）。 我们方法的优势显而易见。 我们在图6中可视化了此数据集的网格池简化的一些示例。我们观察到网格池以一致的语义方式运行（请参见图11）。</p>
<p><strong>Cube engraving</strong>。 为了说明MeshCNN的独特功能，我们对一组带有浅色图标雕刻的立方体进行了建模（请参见图7）。 我们使用MPEG-7二进制形状[Latecki and Lakamper 2000]数据集中的23个类，每个类大约有20个图标。 我们在每个类为测试集预留了三个图标，其余的用于训练。 对于每个图标，我们随机采样10个不同的位置（位置，旋转和立方体面）以插入图标。 每个立方体大约有500个面，这意味着细节丰富的形状在平坦区域中具有较少的三角形，而细部不丰富的形状在平坦区域中具有更多的三角形。 这组包含总共4600个形状，其中训练/测试拆分为3910/690。 我们计划在发布后发布此数据集以及数据综合代码。</p>
<p>我们训练MeshCNN对立方体进行分类。 我们在表2中显示了定量结果。为了可视化网格合并对分类任务的影响，我们在每次网格合并操作之后提取了中间结果（如图8所示）。 观察MeshCNN如何学会减少与分类任务无关的边缘（平坦的立方体表面），同时保留图标雕刻内和周围的边缘。</p>
<p>我们还在此集合上训练了基于点的方法，并在表2中显示了结果。虽然可以认为该示例是人为设计的，但它的目的是要强调MeshCNN在包含较大几何分辨率差异的3D形状上表现出色。</p>
<h3 id="5-3-网格分割"><a href="#5-3-网格分割" class="headerlink" title="5.3 网格分割"></a>5.3 网格分割</h3><p>MeshCNN的另一个应用是一致的形状分割，这是形状分析和合成中许多应用的重要组成部分。 我们使用监督学习来训练MeshCNN，以预测每个边缘在COSEG上属于特定段的概率[Wang等。 2012]和《人体分割》 [Maron等。 2017]数据集。 由于两个数据集都提供了每张脸的地面真相分割，因此我们根据原始分辨率中的标签在简化网格上生成了边缘级语义标签</p>
<p>最直接的MeshCNN语义分段配置是使用一系列网格卷积层（以及归一化和非线性激活单元）。 然而，合并网格池使MeshCNN能够学习由分段驱动的边缘折叠。 回想一下，网格合并降低了输入网格分辨率，该分辨率不再与地面真实边缘级别标签一致。 为此，我们使用网格分解层将分辨率升采样回原始输入大小</p>
<p><strong>COSEG</strong>。 我们在COSEG数据集上的分割任务上评估了MeshCNN的性能，该数据集包含三个大集合：外星人，花瓶和椅子，每个分别包含200、300和400个模型。 我们将每个形状类别划分为85％/ 15％训练/测试划分。 我们将PointNet，PointNet ++和PointCNN进行了比较，并在表3中报告了所有方法的最佳准确性。与该数据集上的所有其他方法相比，我们的技术可获得更好的结果。</p>
<p>我们认为这是由于我们的网络是针对网格结构量身定制的，这使它比其他策略更具优势。 为了进一步证明这一点，我们还报告了随机池化（随机选择折叠的边缘）情况下的结果，并表明这种变化会降低网络的性能。</p>
<p>此外，图9显示了来自MeshCNN语义分段网络的最终分段预测，其中保留了测试集上具有池化层和解池化层。这也表明了执行的池化如何适应目标问题。</p>
<p>人体分割。我们在[Maron et al。提出的人体分割数据集上评估了我们的方法。 2017]。该数据集包含SCAPE的370个训练模型[Anguelov等。 2005]，FAUST [Bogo等。麻省理工学院[2014]。 2008]和Adobe Fuse [Adobe 2016]，测试集是SHREC07的18种模型[Giorgi等。 2007]（人类）数据集。根据[Kaloger akis等人，2000年， 2010]。最近，[Poulenard和Ovsjanikov 2018]在该数据集上报告了其方法的结果，并与GCNN进行了比较[Masci等。 2015]，PointNet ++ [Qi等。 2017b]，动态图CNN [Wang等。 2018b]和Toric Cover [Maron et al。 2017]。我们直接从[Poulenard和Ovsjanikov 2018]中获取报告的结果，并将它们列出在表4中。我们在表中添加了Haim等人的最新结果。 [2018]，报告有关这组电影的最新结果。同样在这种情况下，MeshCNN相对于其他方法（部分基于图形/流形，有些基于点）具有优势，我们认为这是由于MeshCNN对网格结构和手头任务的适应性所致。图10给出了MeshCNN的一些定性结果。</p>
<h3 id="5-4-额外的评估"><a href="#5-4-额外的评估" class="headerlink" title="5.4 额外的评估"></a>5.4 额外的评估</h3><p><strong>计算时间</strong>。 我们未经优化的PyTorch [Paszke等。 [2017年]使用GTX 1080 TI显卡进行2250/750边缘的细分/分类训练时，每个示例平均需要平均0.21 / 0.13秒</p>
<p>镶嵌鲁棒性。 我们通过使用COSEG分割数据集的几个定性和定量实验，检验了我们的方法对三角剖分差异的鲁棒性。 为此，我们生成了数据集的两个修改版本。 第一个是通过应用重新网格化程序（使用Blender和MeshLab）获得的，第二个是通过随机地每折磨30％的顶点位置来实现的，实现为朝其1环中的随机顶点移动。 性能上的细微差异（请参见表5）暗示了对镶嵌细分变化的适应力。 定性结果见图12。</p>
<p>不变特征。 使用相关特征的一个显着优势是，MeshCNN可以保证旋转，平移和统一缩放不变。 本质上，常用的笛卡尔坐标对刚性变换敏感。 为了说明这一点，我们在语义分割任务上训练了MeshCNN：（i）使用不变的几何特征，（ii）使用边缘中点（x，y，z）作为输入特征。 为了评估学习的概括性，我们沿垂直轴应用了非均匀缩放（无需对这些类型的增强进行训练）。 我们的相对几何特征达到98.44％，而标准测试集为99.63％，而绝对坐标恶化为78.27％，而标准测试集为99.11％。 请注意，虽然我们的几何特征对于非均匀缩放不是不变的，但由于它们对定位不敏感，因此它们的泛化效果更好。</p>
<h2 id="6-DISCUSSION-AND-FUTURE-WORK"><a href="#6-DISCUSSION-AND-FUTURE-WORK" class="headerlink" title="6 DISCUSSION AND FUTURE WORK"></a>6 DISCUSSION AND FUTURE WORK</h2><p>我们介绍了MeshCNN，这是一种直接在不规则三角形网格上直接使用神经网络的通用方法。 我们工作的主要贡献是针对不规则和不均匀结构量身定制的卷积和合并操作的定义和应用。 这些操作有助于直接分析以其原始形式表示为网格的形状，并因此受益于与具有不均匀结构的表面歧管的表示相关的独特属性。</p>
<p>不变卷积。 我们选择网格边缘作为网络运行的基本构建块具有重要意义，因为边缘集要求一种简单的方法来定义局部的，固定大小的邻域，用于在不规则结构上进行卷积。 通过利用特定于三角形网格的独特对称性，我们消除了邻居有序对偶性的歧义，以使变换具有不变性。 我们通过选择输入边缘特征来补充这项工作，这些输入边缘特征经过精心策划以仅包含相对几何属性，而不包含绝对位置。 因此，与常见表示形式（例如基于点的表示形式）不同，顶点的笛卡尔坐标被忽略，局部和非局部特征均不受位置影响，从而可以更好地概括形状特征，并有助于不变地进行相似性变换。 我们强调，我们仅将顶点位置用于显示正在演化的网格，但它们的位置对任务没有影响。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/05/28/RDD%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/28/RDD%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/" itemprop="url">RDD编程指南</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-28T11:15:51+08:00">
                2020-05-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>在较高的级别上，每个Spark应用程序由一个驱动程序组成，该驱动程序运行用户的主要功能，并在集群上执行各种并行操作。Spark提供的主要抽象是一个弹性分布式数据集(RDD)，它是一个跨集群节点分区的元素集合，可以并行操作。RDDs的创建是从Hadoop文件系统(或任何其他Hadoop支持的文件系统)中的一个文件开始的，或者是从驱动程序中已有的Scala集合开始的，然后对其进行转换。用户也可以要求Spark将RDD持久化到内存中。</p>
<p>Spark中的第二个抽象是可以在并行操作中使用的共享变量。默认情况下，当Spark作为不同节点上的一组任务并行运行一个函数时，它会将函数中使用的每个变量的副本发送给每个任务。有时候，一个变量需要在任务之间共享，或者在任务和驱动程序之间共享。Spark支持两种类型的共享变量:广播变量(broadcast variable)和累加器(accumulator)，广播变量可用于在所有节点的内存中缓存一个值，累加器是只添加到其中的变量，比如计数器和和。</p>
<p>本指南用Spark支持的每种语言展示了这些特性。It is easiest to follow along with if you launch Spark’s interactive shell – either <code>bin/spark-shell</code> for the Scala shell or <code>bin/pyspark</code> for the Python one.</p>
<h1 id="Linking-with-Spark"><a href="#Linking-with-Spark" class="headerlink" title="Linking with Spark"></a>Linking with Spark</h1><p>Python<br>Spark 2.4.5适用于python2.7 +或python3.4 +。它可以使用标准的CPython解释器，因此可以使用像NumPy这样的C库。它也适用于PyPy 2.3+。<br>可以使用运行时包含Spark的<code>bin/spark-submit</code>脚本运行Python中的Spark应用程序，也可以将其包含在setup.py中，如下所示：</p>
<pre><code class="language-python" data-lang="python"><span></span>    <span class="n">install_requires</span><span class="o">=</span><span class="p">[</span>
        <span class="s1">'pyspark=={site.SPARK_VERSION}'</span>
    <span class="p">]</span></code></pre>
<p>要在Python中运行Spark应用程序而无需pip安装PySpark，请使用位于Spark目录中的<code>bin/spark-submit</code>脚本。 该脚本将加载Spark的Java/Scala库，并允许您将应用程序提交到集群。 您还可以使用<code>bin/pyspark</code>启动交互式Python Shell。</p>
<p>如果您希望访问HDFS数据，则需要使用PySpark构建来链接到您的HDFS版本。在Spark主页上还可以找到用于普通HDFS版本的<a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">预构建包</a>。</p>
<p>最后，您需要将一些Spark类导入程序。添加以下行</p>
<pre><code class="language-python" data-lang="python"><span></span><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span><span class="p">,</span> <span class="n">SparkConf</span></code></pre>

<p>PySpark在驱动程序和工作程序中都需要相同的Python minor版本。它在PATH中使用默认的python版本，例如，您可以指定<code>PYSPARK_PYTHON</code>要使用的python版本</p>
<pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>python3.4 bin/pyspark
$ <span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/opt/pypy-2.5/bin/pypy bin/spark-submit examples/src/main/python/pi.py</code></pre>

<h1 id="Initializing-Spark"><a href="#Initializing-Spark" class="headerlink" title="Initializing Spark"></a>Initializing Spark</h1><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p>Spark程序必须做的第一件事是创建一个<a href="https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext" target="_blank" rel="noopener">SparkContext</a>对象，它告诉Spark如何访问集群。要创建SparkContext，首先需要构建一个<a href="https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext" target="_blank" rel="noopener">SparkConf</a>对象，该对象包含关于应用程序的信息。</p>
<pre><code class="language-python" data-lang="python"><span></span><span class="n">conf</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span><span class="o">.</span><span class="n">setAppName</span><span class="p">(</span><span class="n">appName</span><span class="p">)</span><span class="o">.</span><span class="n">setMaster</span><span class="p">(</span><span class="n">master</span><span class="p">)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span></code></pre>

<p><code>appName</code>参数是应用程序在集群UI上显示的名称。<code>master</code>是一个<a href="https://spark.apache.org/docs/latest/submitting-applications.html#master-urls" target="_blank" rel="noopener">Spark、Mesos或YARN集群的URL</a>，或者在本地模式下运行的特殊本地字符串。实际上，在集群上运行时，您不希望在程序中硬编码master，而是<a href="https://spark.apache.org/docs/latest/submitting-applications.html" target="_blank" rel="noopener">使用spark-submit启动应用程序</a>并在那里接收它。但是，对于本地测试和单元测试，可以通过<code>local</code>来运行Spark in-process。</p>
<h3 id="Using-the-Shell"><a href="#Using-the-Shell" class="headerlink" title="Using the Shell"></a>Using the Shell</h3><p>在PySpark shell中，已经在名为sc的变量中为您创建了一个特殊的可识别解释程序的SparkContext。 制作自己的SparkContext将不起作用。 您可以使用<code>--master</code>参数设置上下文连接的主机，也可以通过将逗号分隔的列表传递给<code>--py-files</code>，将Python .zip，.egg或.py文件添加到运行时路径。 您还可以通过在<code>--packages</code>参数中提供逗号分隔的Maven坐标列表，从而将依赖项（例如Spark Packages）添加到Shell会话中。 可以存在依赖项的任何其他存储库（例如Sonatype）都可以传递给<code>--repositories</code>参数。 必要时，必须使用pip手动安装Spark软件包具有的所有Python依赖项（在该软件包的requirements.txt中列出）。 例如，要在正好四个内核上运行<code>bin/pyspark</code>，请使用：</p>
<pre><code class="language-bash" data-lang="bash"><span></span>$ ./bin/pyspark --master local<span class="o">[</span><span class="m">4</span><span class="o">]</span></code></pre>

<p>或者，也可以将code.py添加到搜索路径(以便以后能够导入代码)，使用</p>
<p><code class="language-bash" data-lang="bash"><span></span>$ ./bin/pyspark --master local<span class="o">[</span><span class="m">4</span><span class="o">]</span> --py-files code.py</code></p>
<p>要获得完整的选项列表，请运行<code>pyspark --help</code>。在幕后，pyspark调用更通用的<a href="https://spark.apache.org/docs/latest/submitting-applications.html" target="_blank" rel="noopener">spark-submit脚本</a>。</p>
<p>也可以在增强的Python解释器IPython中启动PySpark Shell。 PySpark可与IPython 1.0.0及更高版本一起使用。 要使用IPython，请在运行<code>bin / pyspark</code>时将<code>PYSPARK_DRIVER_PYTHON</code>变量设置为ipython：</p>
<pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>ipython ./bin/pyspark</code></pre>

<p>使用jupyter notebook(以前称为IPython notebook)</p>
<p><code class="language-bash" data-lang="bash"><span></span>$ <span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>jupyter <span class="nv">PYSPARK_DRIVER_PYTHON_OPTS</span><span class="o">=</span>notebook ./bin/pyspark</code></p>
<p>您可以通过设置<code>PYSPARK_DRIVER_PYTHON_OPTS</code>来定制ipython或jupyter命令。</p>
<p>启动Jupyter Notebook服务器后，您可以从“文件”选项卡创建一个新的“ Python 2”笔记本。 在笔记本内部，您可以在笔记本中开始内联输入命令<code>％pylab inline</code>作为笔记本的一部分，然后再从Jupyter笔记本开始尝试Spark。</p>
<h1 id="弹性分布式数据集Resilient-Distributed-Datasets-RDDs"><a href="#弹性分布式数据集Resilient-Distributed-Datasets-RDDs" class="headerlink" title="弹性分布式数据集Resilient Distributed Datasets (RDDs)"></a>弹性分布式数据集Resilient Distributed Datasets (RDDs)</h1><p>Spark围绕弹性分布式数据集(RDD)的概念，它是一组可以并行操作的元素的容错集合。创建RDDs有两种方法:并行化驱动程序中的现有集合，或者引用外部存储系统中的数据集，例如共享文件系统、HDFS、HBase或任何提供Hadoop InputFormat的数据源。</p>
<h1 id="并行集合Parallelized-Collections"><a href="#并行集合Parallelized-Collections" class="headerlink" title="并行集合Parallelized Collections"></a>并行集合Parallelized Collections</h1><h2 id="Python-1"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h2><p>通过在驱动程序中现有的iterable或集合上调用<code>SparkContext&#39;s parallelize</code>方法来创建并行集合。将集合的元素复制以形成可并行操作的分布式数据集。例如，下面是如何创建一个包含数字1到5的并行集合</p>
<pre><code class="language-python" data-lang="python"><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">distData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span></code></pre>

<p>一旦创建，分布式数据集(distData)就可以并行操作。例如，我们可以调用distData。减少(lambda a, b: a + b)将列表中的元素相加。稍后我们将描述对分布式数据集的操作。</p>
<p>并行集合的一个重要参数是要将数据集分割成多少个分区。Spark将为集群的每个分区运行一个任务。通常，集群中的每个CPU需要2-4个分区。通常，Spark尝试根据您的集群自动设置分区的数量。但是，您也可以通过将其作为第二个参数传递来手动设置它<code>parallelize</code>(例如，<code>sc.parallelize(data, 10))</code>。注意:代码中的某些地方使用术语片(分区的同义词)来保持向后兼容性。</p>
<h1 id="外部数据集External-Datasets"><a href="#外部数据集External-Datasets" class="headerlink" title="外部数据集External Datasets"></a>外部数据集External Datasets</h1><p>PySpark可以从Hadoop支持的任何存储源创建分布式数据集，包括本地文件系统、HDFS、Cassandra、HBase、Amazon S3等。Spark支持文本文件、<a href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapred/SequenceFileInputFormat.html" target="_blank" rel="noopener">SequenceFiles</a>和任何其他<a href="http://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/InputFormat.html" target="_blank" rel="noopener">Hadoop InputFormat</a>。</p>
<p>可以使用<code>SparkContext&#39;s textFile</code>方法创建文本文件RDD。 此方法获取文件的URI（计算机上的本地路径，或<code>hdfs：//，s3a：//</code>等URI），并将其读取为行的集合。 这是一个示例调用：</p>
<pre><code class="language-python" data-lang="python"><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">distFile</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">"data.txt"</span><span class="p">)</span></code></pre>

<p>创建distFile之后，就可以通过数据集操作对其进行操作。例如，我们可以使用映射将所有行的大小相加并按如下方式归约操作:<code>distFile.map(lambda s: len(s)).reduce(lambda a, b: a + b)</code>。</p>
<p>一些关于使用Spark读取文件的注意事项</p>
<ul>
<li>如果使用本地文件系统上的路径，则该文件也必须在工作节点上的相同路径上可访问。将文件复制到所有worker，或者使用挂载在网络上的共享文件系统。</li>
<li>所有基于Spark文件的输入方法，包括<code>textFile</code>，都支持在目录、压缩文件和通配符上运行。例如，你可以使用<code>textFile(&quot;/my/directory&quot;), textFile(&quot;/my/directory/*.txt&quot;), and textFile(&quot;/my/directory/*.gz&quot;)</code>。</li>
<li><code>textFile</code>方法还接受一个可选的第二个参数，用于控制文件的分区数量。默认情况下，Spark为文件的每个块创建一个分区(在HDFS中，块的默认大小为128MB)，但是您也可以通过传递更大的值来请求更多的分区。注意，分区不能少于块。</li>
</ul>
<p>除了文本文件之外，Spark’s Python API还支持其他几种数据格式</p>
<ul>
<li><code>SparkContext.wholeTextFiles</code>允许您读取包含多个小文本文件的目录，并以(文件名、内容)对的形式返回每个文件。这与textFile相反，textFile在每个文件中每行返回一条记录。</li>
<li><code>RDD.saveAsPickleFile</code> 和<code>SparkContext.pickleFile</code>支持以包含pickle的Python对象的简单格式保存RDD。批处理用于pickle序列化，默认批处理大小为10。</li>
<li>SequenceFile and Hadoop Input/Output Formats</li>
</ul>
<p><strong>Note</strong> this feature is currently marked <code>Experimental</code> and is intended for advanced users. It may be replaced in future with read/write support based on Spark SQL, in which case Spark SQL is the preferred approach.</p>

<p><strong>Writable Support</strong></p>
<p>PySpark SequenceFile支持在Java中加载一个键-值对的RDD，将可写对象转换为基本Java类型，并使用<a href="https://github.com/irmen/Pyrolite/" target="_blank" rel="noopener">Pyrolite</a> pickle生成的Java对象。当将键值对的RDD保存到SequenceFile时，PySpark执行相反的操作。它将Python对象解pickle为Java对象，然后将它们转换为可写对象。下面的可写内容会自动转换</p>
<table class="table">
<tbody><tr><th>Writable Type</th><th>Python Type</th></tr>
<tr><td>Text</td><td>unicode str</td></tr>
<tr><td>IntWritable</td><td>int</td></tr>
<tr><td>FloatWritable</td><td>float</td></tr>
<tr><td>DoubleWritable</td><td>float</td></tr>
<tr><td>BooleanWritable</td><td>bool</td></tr>
<tr><td>BytesWritable</td><td>bytearray</td></tr>
<tr><td>NullWritable</td><td>None</td></tr>
<tr><td>MapWritable</td><td>dict</td></tr>
</tbody></table>

<p>数组不是开箱即用的。在读取或写入时，用户需要指定自定义ArrayWritable子类型。在编写时，用户还需要指定将数组转换为自定义ArrayWritable子类型的自定义转换器。读取时，默认转换器将自定义ArrayWritable子类型转换为Java Object[]，然后将其pickle为Python元组。获取Python数组。对于基元类型的数组，用户需要指定自定义转换器。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/05/28/SparkOverview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/28/SparkOverview/" itemprop="url">SparkOverview</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-28T10:12:42+08:00">
                2020-05-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Spark-Overview"><a href="#Spark-Overview" class="headerlink" title="Spark Overview"></a><a href="https://spark.apache.org/docs/latest/index.html#spark-overview" target="_blank" rel="noopener">Spark Overview</a></h1><p>Apache的Spark是一种快速和通用集群计算系统。它提供了在Java中，Scala中，Python的和R高层API，和优化引擎，支持一般的执行的图。它还支持一组丰富的更高级别的工具，包括SPARK SQL为SQL和结构化数据的处理，MLlib机器学习，GraphX用于图形处理和Spark Streaming。</p>
<h1 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h1><p>Spark中的安全性在默认情况下是关闭的。这可能意味着您在默认情况下很容易受到攻击。请在下载并运行Spark之前查看Spark安全性。</p>
<h1 id="Downloading"><a href="#Downloading" class="headerlink" title="Downloading"></a>Downloading</h1><h1 id="运行示例和Shell"><a href="#运行示例和Shell" class="headerlink" title="运行示例和Shell"></a>运行示例和Shell</h1><p>Spark附带了几个示例程序. Scala, Java, Python and R examples are in the examples<code>/src/main directory</code>. To run one of the Java or Scala sample programs, use <code>bin/run-example &lt;class&gt; [params]</code> in the top-level Spark directory. (在幕后，这将调用更通用的spark-submit脚本来启动应用程序). 例如,</p>
<pre>
    <code>./bin/run-example SparkPi 10</code>
</pre>
<p>您还可以通过修改过的Scala shell交互式地运行Spark。这是学习框架的好方法。</p>
<pre><code>./bin/spark-shell --master local[2]
</code></pre>

<p><code>--master</code>选项指定一个分布式集群的master URL，或者<code>local</code>指定一个线程在local运行local URL，或者<code>loacl[N]</code>在本地运行N个线程。您应该首先使用<code>local</code>进行测试。要获得完整的选项列表，请使用<code>--help</code>选项运行Spark shell。</p>
<p>Spark提供了Python的API，使用<code>bin/pyspark</code>在Python解释器中交互式地运行Spark。</p>
<pre><code>./bin/pyspark --master local[2]
</code></pre>
<p>还用Python提供了示例应用程序。例如</p>
<pre><code>./bin/spark-submit examples/src/main/python/pi.py 10
</code></pre>

<p>Spark also provides an experimental <a href="sparkr.html">R API</a> since 1.4 (only DataFrames APIs included).
To run Spark interactively in a R interpreter, use <code>bin/sparkR</code>:</p>

<pre><code>./bin/sparkR --master local[2]
</code></pre>

<p>Example applications are also provided in R. For example,</p>

<pre><code>./bin/spark-submit examples/src/main/r/dataframe.R
</code></pre>

<h1 id="在集群上启动"><a href="#在集群上启动" class="headerlink" title="在集群上启动"></a>在集群上启动</h1><p><a href="https://spark.apache.org/docs/latest/cluster-overview.html" target="_blank" rel="noopener">Spark集群模式</a>概述解释了在集群上运行的关键概念。Spark既可以自己运行，也可以在多个现有集群管理器上运行。它目前提供了几个部署选项</p>
<ul>
  <li><a href="spark-standalone.html">Standalone Deploy Mode</a>: simplest way to deploy Spark on a private cluster</li>
  <li><a href="running-on-mesos.html">Apache Mesos</a></li>
  <li><a href="running-on-yarn.html">Hadoop YARN</a></li>
  <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
</ul>

<h1 id="Where-to-Go-from-Here"><a href="#Where-to-Go-from-Here" class="headerlink" title="Where to Go from Here"></a>Where to Go from Here</h1><p><strong>Programming Guides:</strong></p>
<ul>
  <li><a href="quick-start.html">Quick Start</a>: a quick introduction to the Spark API; start here!</li>
  <li><a href="rdd-programming-guide.html">RDD Programming Guide</a>: overview of Spark basics - RDDs (core but old API), accumulators, and broadcast variables</li>
  <li><a href="sql-programming-guide.html">Spark SQL, Datasets, and DataFrames</a>: processing structured data with relational queries (newer API than RDDs)</li>
  <li><a href="structured-streaming-programming-guide.html">Structured Streaming</a>: processing structured data streams with relation queries (using Datasets and DataFrames, newer API than DStreams)</li>
  <li><a href="streaming-programming-guide.html">Spark Streaming</a>: processing data streams using DStreams (old API)</li>
  <li><a href="ml-guide.html">MLlib</a>: applying machine learning algorithms</li>
  <li><a href="graphx-programming-guide.html">GraphX</a>: processing graphs</li>
</ul>

<p><strong>API Docs:</strong></p>

<ul>
  <li><a href="api/scala/index.html#org.apache.spark.package">Spark Scala API (Scaladoc)</a></li>
  <li><a href="api/java/index.html">Spark Java API (Javadoc)</a></li>
  <li><a href="api/python/index.html">Spark Python API (Sphinx)</a></li>
  <li><a href="api/R/index.html">Spark R API (Roxygen2)</a></li>
  <li><a href="api/sql/index.html">Spark SQL, Built-in Functions (MkDocs)</a></li>
</ul>

<p><strong>Deployment Guides:</strong></p>

<ul>
  <li><a href="cluster-overview.html">Cluster Overview</a>: overview of concepts and components when running on a cluster</li>
  <li><a href="submitting-applications.html">Submitting Applications</a>: packaging and deploying applications</li>
  <li>Deployment modes:
    <ul>
      <li><a href="https://github.com/amplab/spark-ec2" target="_blank" rel="noopener">Amazon EC2</a>: scripts that let you launch a cluster on EC2 in about 5 minutes</li>
      <li><a href="spark-standalone.html">Standalone Deploy Mode</a>: launch a standalone cluster quickly without a third-party cluster manager</li>
      <li><a href="running-on-mesos.html">Mesos</a>: deploy a private cluster using
  <a href="https://mesos.apache.org" target="_blank" rel="noopener">Apache Mesos</a></li>
      <li><a href="running-on-yarn.html">YARN</a>: deploy Spark on top of Hadoop NextGen (YARN)</li>
      <li><a href="running-on-kubernetes.html">Kubernetes</a>: deploy Spark on top of Kubernetes</li>
    </ul>
  </li>
</ul>

<p><strong>Other Documents:</strong></p>

<ul>
  <li><a href="configuration.html">Configuration</a>: customize Spark via its configuration system</li>
  <li><a href="monitoring.html">Monitoring</a>: track the behavior of your applications</li>
  <li><a href="tuning.html">Tuning Guide</a>: best practices to optimize performance and memory use</li>
  <li><a href="job-scheduling.html">Job Scheduling</a>: scheduling resources across and within Spark applications</li>
  <li><a href="security.html">Security</a>: Spark security support</li>
  <li><a href="hardware-provisioning.html">Hardware Provisioning</a>: recommendations for cluster hardware</li>
  <li>Integration with other storage systems:
    <ul>
      <li><a href="cloud-integration.html">Cloud Infrastructures</a></li>
      <li><a href="storage-openstack-swift.html">OpenStack Swift</a></li>
    </ul>
  </li>
  <li><a href="building-spark.html">Building Spark</a>: build Spark using the Maven system</li>
  <li><a href="https://spark.apache.org/contributing.html" target="_blank" rel="noopener">Contributing to Spark</a></li>
  <li><a href="https://spark.apache.org/third-party-projects.html" target="_blank" rel="noopener">Third Party Projects</a>: related third party Spark projects</li>
</ul>

<p><strong>External Resources:</strong></p>

<ul>
  <li><a href="https://spark.apache.org" target="_blank" rel="noopener">Spark Homepage</a></li>
  <li><a href="https://spark.apache.org/community.html" target="_blank" rel="noopener">Spark Community</a> resources, including local meetups</li>
  <li><a href="http://stackoverflow.com/questions/tagged/apache-spark" target="_blank" rel="noopener">StackOverflow tag <code>apache-spark</code></a></li>
  <li><a href="https://spark.apache.org/mailing-lists.html" target="_blank" rel="noopener">Mailing Lists</a>: ask questions about Spark here</li>
  <li><a href="http://ampcamp.berkeley.edu/" target="_blank" rel="noopener">AMP Camps</a>: a series of training camps at UC Berkeley that featured talks and
exercises about Spark, Spark Streaming, Mesos, and more. <a href="http://ampcamp.berkeley.edu/6/" target="_blank" rel="noopener">Videos</a>,
<a href="http://ampcamp.berkeley.edu/6/" target="_blank" rel="noopener">slides</a> and <a href="http://ampcamp.berkeley.edu/6/exercises/" target="_blank" rel="noopener">exercises</a> are
available online for free.</li>
  <li><a href="https://spark.apache.org/examples.html" target="_blank" rel="noopener">Code Examples</a>: more are also available in the <code>examples</code> subfolder of Spark (<a href="https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples" target="_blank" rel="noopener">Scala</a>,
 <a href="https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples" target="_blank" rel="noopener">Java</a>,
 <a href="https://github.com/apache/spark/tree/master/examples/src/main/python" target="_blank" rel="noopener">Python</a>,
 <a href="https://github.com/apache/spark/tree/master/examples/src/main/r" target="_blank" rel="noopener">R</a>)</li>
</ul>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/05/26/MPITutorials/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/26/MPITutorials/" itemprop="url">MPITutorials</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-26T17:42:38+08:00">
                2020-05-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>ref:<a href="https://computing.llnl.gov/tutorials/mpi/" target="_blank" rel="noopener">Message Passing Interface (MPI)</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>消息传递接口标准（MPI）是基于MPI论坛共识的消息传递库标准，MPI论坛有40多个参与组织，其中包括供应商，研究人员，软件库开发人员和用户。消息传递接口的目标是为消息传递建立一种可移植，高效且灵活的标准，该标准将广泛用于编写消息传递程序。因此，MPI是第一个标准化的，独立于供应商的消息传递库。使用MPI开发消息传递软件的优势与可移植性，效率和灵活性的设计目标紧密匹配。 MPI不是IEEE或ISO标准，但实际上已成为在HPC平台上编写消息传递程序的“行业标准”。</p>
<p>本教程的目的是教那些不熟悉MPI的人如何根据MPI标准开发和运行并行程序。提出的主要主题集中于对新MPI程序员最有用的主题。本教程首先介绍MPI入门，背景和基本信息。接下来是对MPI例程的详细介绍，这些例程对新MPI程序员最有用，包括MPI环境管理，点对点通信和集体通信例程。提供了C和Fortran中的大量示例以及实验室练习。</p>
<p>教程材料还包括更高级的主题，例如“派生数据类型”，“组和Communicator管理例程”以及“虚拟拓扑”。但是，这些实际上并没有在讲座中介绍，而是为那些有兴趣的人提供“进一步的阅读”。</p>
<h2 id="什么是MPI"><a href="#什么是MPI" class="headerlink" title="什么是MPI"></a>什么是MPI</h2><h3 id="一种接口规范"><a href="#一种接口规范" class="headerlink" title="一种接口规范"></a>一种接口规范</h3><ul>
<li>M P I = Message Passing Interface</li>
<li>MPI是针对消息传递库的开发人员和用户的规范。 就其本身而言，它不是一个库-而是有关该库应该是什么的规范。</li>
<li>简而言之，消息传递接口的目的是为编写消息传递程序提供广泛使用的标准。 该接口尝试是：<ul>
<li>Practical </li>
<li>Portable </li>
<li>Efficient </li>
<li>Flexible </li>
</ul>
</li>
<li>MPI标准已进行了许多修订，最新版本为MPI-3.x。</li>
<li>已经为C和Fortran90语言绑定定义了接口规范：</li>
<li>实际的MPI库实现在支持的MPI标准的版本和功能方面有所不同。 开发人员/用户将需要意识到这一点。</li>
</ul>
<h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><ul>
<li>MPI最初是为分布式内存体系结构设计的，该体系结构在当时（1980年代-1990年代初期）变得越来越流行。</li>
<li>随着架构趋势的变化，共享内存SMP通过网络进行组合，从而创建了混合分布式内存/共享内存系统。</li>
<li>MPI实现者调整了其库，以无缝处理两种类型的基础内存体系结构。 他们还采用/开发了处理不同互连和协议的方式。</li>
<li>如今，MPI几乎可以在任何硬件平台上运行：<ul>
<li>Distributed Memory </li>
<li>Shared Memory </li>
<li>Hybrid</li>
</ul>
</li>
<li>但是，无论机器的基础物理体系结构如何，编程模型显然仍然是分布式内存模型。</li>
<li>所有并行性都是明确的：程序员负责正确识别并行性并使用MPI构造实现并行算法。</li>
</ul>
<h3 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h3><ul>
<li>有关MPI标准所有版本的文档，请访问：<a href="http：//www.mpi-forum.org/docs/">http：//www.mpi-forum.org/docs/</a>。</li>
</ul>
<h2 id="LLNL-MPI-Implementations-and-Compilers"><a href="#LLNL-MPI-Implementations-and-Compilers" class="headerlink" title="LLNL MPI Implementations and Compilers"></a>LLNL MPI Implementations and Compilers</h2><h2 id="开始学习"><a href="#开始学习" class="headerlink" title="开始学习"></a>开始学习</h2><h3 id="一般的MPI编程结构"><a href="#一般的MPI编程结构" class="headerlink" title="一般的MPI编程结构"></a>一般的MPI编程结构</h3><p><img src="MPITutorials/prog_structure.gif" alt="prog_structure"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include "mpi.h"</span></span><br><span class="line"><span class="comment">#include &lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;stdlib.h&gt;</span></span><br><span class="line"></span><br><span class="line">int main (int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">int numtasks, rank, dest, <span class="built_in">source</span>, rc, count, tag=1;</span><br><span class="line">char inmsg, outmsg=<span class="string">'x'</span>;</span><br><span class="line">MPI_Status Stat;</span><br><span class="line"></span><br><span class="line">MPI_Init(&amp;argc,&amp;argv);</span><br><span class="line">MPI_Comm_size(MPI_COMM_WORLD, &amp;numtasks);</span><br><span class="line">MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (rank == 0) &#123;</span><br><span class="line">  dest = 1;</span><br><span class="line">  <span class="built_in">source</span> = 1;</span><br><span class="line">  rc = MPI_Send(&amp;outmsg, 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);</span><br><span class="line">  rc = MPI_Recv(&amp;inmsg, 1, MPI_CHAR, <span class="built_in">source</span>, tag, MPI_COMM_WORLD, &amp;Stat);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (rank == 1) &#123;</span><br><span class="line">  dest = 0;</span><br><span class="line">  <span class="built_in">source</span> = 0;</span><br><span class="line">  rc = MPI_Recv(&amp;inmsg, 1, MPI_CHAR, <span class="built_in">source</span>, tag, MPI_COMM_WORLD, &amp;Stat);</span><br><span class="line">  rc = MPI_Send(&amp;outmsg, 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h3><ul>
<li><p>所有进行MPI库调用的程序都必需。</p>
<table border="1">
  <tr>
      <th>C include file </th>
      <th>Fortran include file</th>
  </tr>
  <tr>
      <td>#include "mpi.h" </td>
      <td>    include 'mpif.h' </td>
  </tr>
</table>
</li>
<li><p>MPI调用格式</p>
<table>
  <tr>
      <th colspan=2>C Binding</th>
  </tr>
  <tr>
      <th>Format:</th>
      <td>rc = MPI_Xxxxx(parameter, ... )</td>
  </tr>
  <tr>
      <th>Example:</th>
      <td>rc = MPI_Bsend(&buf,count,type,dest,tag,comm) </td>
  <tr>
      <th>Error code:</th>
      <td>Returned as "rc". MPI_SUCCESS if successful </td>
  </tr>
</table>

</li>
</ul>
<h3 id="Communicators-and-Groups"><a href="#Communicators-and-Groups" class="headerlink" title="Communicators and Groups:"></a>Communicators and Groups:</h3><ul>
<li>MPI使用称为通信器和组的对象来定义哪些进程集合可以相互通信。</li>
<li>大多数MPI例程都要求您指定一个通讯器作为参数。</li>
<li>大多数MPI例程都要求您指定一个通讯器作为参数。</li>
<li>通讯器和组将在后面详细介绍。 现在，只要需要通信器，就只需使用MPI_COMM_WORLD-它是预定义的通信器，它包含所有MPI进程。<br><img src="MPITutorials/comm_world.gif" alt="comm_world"></li>
</ul>
<h3 id="Rank"><a href="#Rank" class="headerlink" title="Rank:"></a>Rank:</h3><ul>
<li>在通信器中，每个进程都有自己的唯一整数标识符，该标识符在进程初始化时由系统分配。 rank有时也称为“任务ID”。 rank是连续的，从零开始。</li>
<li>程序员用来指定消息的源和目标。 通常由应用程序有条件地用来控制程序的执行（如果rank = 0则执行此操作，如果rank = 1则执行此操作）。</li>
</ul>
<h3 id="Error-Handling"><a href="#Error-Handling" class="headerlink" title="Error Handling:"></a>Error Handling:</h3><ul>
<li>如上面“ MPI调用的格式”部分中所述，大多数MPI例程都包含返回/错误代码参数。</li>
<li>但是，根据MPI标准，如果发生错误，MPI调用的默认行为是中止。 这意味着您可能将无法捕获MPI_SUCCESS（零）以外的返回/错误代码。</li>
<li>该标准确实提供了覆盖此默认错误处理程序的方法。 此处提供有关如何执行此操作的讨论。 您也可以参考<a href="http://www.mpi-forum.org/docs/" target="_blank" rel="noopener">http://www.mpi-forum.org/docs/</a>上相关MPI标准文档的错误处理部分。</li>
<li>向用户显示的错误类型取决于实现。</li>
</ul>
<h2 id="环境管理程序"><a href="#环境管理程序" class="headerlink" title="环境管理程序"></a>环境管理程序</h2><p>这套例程用于询问和设置MPI执行环境，并涵盖了多种目的，例如初始化和终止MPI环境，查询rank的identity，查询MPI库的版本等。大多数常用的例程如下所述。</p>
<h3 id="MPI-Init"><a href="#MPI-Init" class="headerlink" title="MPI_Init"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Init.txt" target="_blank" rel="noopener">MPI_Init</a></h3><p>初始化MPI执行环境。 必须在每个MPI程序中调用此函数，必须在任何其他MPI函数之前调用此函数，并且在MPI程序中只能调用一次。 对于C程序，MPI_Init可以用于将命令行参数传递给所有进程，尽管这不是标准要求的，并且取决于实现。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Init (&amp;argc,&amp;argv)</span><br><span class="line">MPI_INIT (ierr)</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Comm-size"><a href="#MPI-Comm-size" class="headerlink" title="MPI_Comm_size"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Comm_size.txt" target="_blank" rel="noopener">MPI_Comm_size</a></h3><p>返回指定通信器中MPI进程的总数，例如MPI_COMM_WORLD。 如果通信器是MPI_COMM_WORLD，则它表示应用程序可用的MPI任务数。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Comm_size (comm,&amp;<span class="built_in">size</span>)</span><br><span class="line">MPI_COMM_SIZE (comm,<span class="built_in">size</span>,ierr)</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Comm-rank"><a href="#MPI-Comm-rank" class="headerlink" title="MPI_Comm_rank"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Comm_rank.txt" target="_blank" rel="noopener">MPI_Comm_rank</a></h3><p>返回指定通信器中调用MPI进程的rank。 最初，在通信器MPI_COMM_WORLD中，将为每个进程分配一个介于0和任务数-1之间的唯一整数rank。 该rank通常称为任务ID。 如果一个进程与其他通讯器相关联，那么在每个通讯器中也将具有唯一的rank。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Comm_rank (comm,&amp;rank)</span><br><span class="line">MPI_COMM_RANK (comm,rank,ierr)</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Abort"><a href="#MPI-Abort" class="headerlink" title="MPI_Abort"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Abort.txt" target="_blank" rel="noopener">MPI_Abort</a></h3><p>终止与通信器关联的所有MPI进程。 在大多数MPI实现中，无论指定哪个通信器，它都会终止所有进程。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Abort (comm,errorcode)</span><br><span class="line">MPI_ABORT (comm,errorcode,ierr)</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Get-processor-name"><a href="#MPI-Get-processor-name" class="headerlink" title="MPI_Get_processor_name"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Get_processor_name.txt" target="_blank" rel="noopener">MPI_Get_processor_name</a></h3><p>返回进程名称。 还返回名称的长度。 “名称”的缓冲区的大小必须至少为MPI_MAX_PROCESSOR_NAME个字符。 返回到“名称”中的是与实现相关的-可能与“主机名”或“主机” shell命令的输出不同。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Get_processor_name (&amp;name,&amp;resultlength)</span><br><span class="line">MPI_GET_PROCESSOR_NAME (name,resultlength,ierr)</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Get-version"><a href="#MPI-Get-version" class="headerlink" title="MPI_Get_version"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Get_version.txt" target="_blank" rel="noopener">MPI_Get_version</a></h3><p>返回由库实现的MPI标准的版本和Subversion。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Get_version (&amp;version,&amp;subversion)</span><br><span class="line">MPI_GET_VERSION (version,subversion,ierr)</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Initialized"><a href="#MPI-Initialized" class="headerlink" title="MPI_Initialized"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Initialized.txt" target="_blank" rel="noopener">MPI_Initialized</a></h3><p>指示是否已调用MPI_Init-将标志返回为逻辑true（1）或false（0）。 MPI要求每个进程仅一次调用MPI_Init。 对于想要使用MPI并准备在必要时调用MPI_Init的模块，这可能会带来问题。 MPI_Initialized解决了此问题。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Initialized (&amp;flag)</span><br><span class="line">MPI_INITIALIZED (flag,ierr)</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Wtime"><a href="#MPI-Wtime" class="headerlink" title="MPI_Wtime"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Wtime.txt" target="_blank" rel="noopener">MPI_Wtime</a></h3><p>返回调用处理器上经过的挂钟时间，以秒为单位（双精度）。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Wtime ()</span><br><span class="line">MPI_WTIME ()</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Wtick"><a href="#MPI-Wtick" class="headerlink" title="MPI_Wtick"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Wtick.txt" target="_blank" rel="noopener">MPI_Wtick</a></h3><p>返回MPI_Wtime的分辨率（以秒为单位）（双精度）。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Wtick ()</span><br><span class="line">MPI_WTICK ()</span><br></pre></td></tr></table></figure>

<h3 id="MPI-Finalize"><a href="#MPI-Finalize" class="headerlink" title="MPI_Finalize"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Finalize.txt" target="_blank" rel="noopener">MPI_Finalize</a></h3><p>终止MPI执行环境。 此函数应该是每个MPI程序中最后一个调用的MPI例程-此后不得再调用其他MPI例程。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Finalize ()</span><br><span class="line">MPI_FINALIZE (ierr)</span><br></pre></td></tr></table></figure>

<h2 id="Examples-Environment-Management-Routines"><a href="#Examples-Environment-Management-Routines" class="headerlink" title="Examples: Environment Management Routines"></a>Examples: Environment Management Routines</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// required MPI include file  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"mpi.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">   <span class="keyword">int</span>  numtasks, rank, len, rc; </span><br><span class="line">   <span class="keyword">char</span> hostname[MPI_MAX_PROCESSOR_NAME];</span><br><span class="line"></span><br><span class="line">   <span class="comment">// initialize MPI  </span></span><br><span class="line">   MPI_Init(&amp;argc,&amp;argv);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// get number of tasks </span></span><br><span class="line">   MPI_Comm_size(MPI_COMM_WORLD,&amp;numtasks);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// get my rank  </span></span><br><span class="line">   MPI_Comm_rank(MPI_COMM_WORLD,&amp;rank);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// this one is obvious  </span></span><br><span class="line">   MPI_Get_processor_name(hostname, &amp;len);</span><br><span class="line">   <span class="built_in">printf</span> (<span class="string">"Number of tasks= %d My rank= %d Running on %s\n"</span>, numtasks,rank,hostname);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// do some work with message passing </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="comment">// done with MPI  </span></span><br><span class="line">   MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="MPI-Exercise-1"><a href="#MPI-Exercise-1" class="headerlink" title="MPI Exercise 1"></a>MPI Exercise 1</h2><p><strong><a href="https://computing.llnl.gov/tutorials/mpi/exercise.html" target="_blank" rel="noopener"> GO TO THE EXERCISE HERE </a></strong></p>
<h2 id="点对点通讯程序"><a href="#点对点通讯程序" class="headerlink" title="点对点通讯程序"></a>点对点通讯程序</h2><h3 id="一般概念"><a href="#一般概念" class="headerlink" title="一般概念"></a>一般概念</h3><h4 id="First-a-Simple-Example"><a href="#First-a-Simple-Example" class="headerlink" title="First, a Simple Example:"></a>First, a Simple Example:</h4><p><strong>以后再翻译</strong></p>
<h4 id="点对点操作的类型"><a href="#点对点操作的类型" class="headerlink" title="点对点操作的类型"></a>点对点操作的类型</h4><ul>
<li>MPI点对点操作通常涉及两个(而且只有两个)不同MPI任务之间的消息传递。一个任务执行发送操作，另一个任务执行匹配的接收操作。</li>
<li>有不同类型的发送和接收例程用于不同的目的。例如<ul>
<li>同步发送</li>
<li>阻塞发送 / 阻塞接收</li>
<li>非阻塞发送和非阻塞接收</li>
<li>缓冲发送</li>
<li>联合发送/接收</li>
<li>“准备好”发送</li>
</ul>
</li>
<li>任何类型的发送例程都可以与任何类型的接收例程配对。</li>
<li>MPI还提供了几个与发送-接收操作相关的例程，比如那些用于等待消息到达或探测消息是否到达的例程。</li>
</ul>
<h4 id="Buffering"><a href="#Buffering" class="headerlink" title="Buffering:"></a>Buffering:</h4><ul>
<li>在一个完美的世界中，每个发送操作都将与它匹配的接收操作完全同步。这种情况很少发生。无论如何，MPI实现必须能够在两个任务不同步时处理存储数据。</li>
<li>考虑以下两种情况<ul>
<li>发送操作在接收准备就绪前5秒发生，在等待接收时，消息在哪里？</li>
<li>多个发送到达同一个接收任务，一次只能接收一个发送——正在“备份”的消息会发生什么</li>
</ul>
</li>
<li>MPI实现(不是MPI标准)决定在这些类型的情况下对数据进行什么处理。通常，保留一个系统缓冲区来保存传输中的数据。例如<br>此处应该有图片</li>
<li>系统缓冲区空间为：<ul>
<li>对程序员来说是不透明的，完全由MPI库管理</li>
<li>一种很容易耗尽的有限资源</li>
<li>通常是神秘的，没有很好的记录</li>
<li>能够存在于发送端、接收端或两者都存在</li>
<li>可以提高程序性能，因为它允许发送-接收操作是异步的。</li>
</ul>
</li>
<li>用户管理的地址空间(即你的程序变量)称为<strong>应用程序缓冲区</strong>。MPI还提供了一个用户管理的发送缓冲区。</li>
</ul>
<h4 id="阻塞和非阻塞"><a href="#阻塞和非阻塞" class="headerlink" title="阻塞和非阻塞:"></a>阻塞和非阻塞:</h4><ul>
<li>大多数MPI点对点例程可以在阻塞或非阻塞模式下使用。</li>
<li><strong>阻塞：</strong><ul>
<li>阻塞发送例程只会在安全修改应用程序缓冲区(您的发送数据)以便重用后“返回”。安全意味着修改不会影响接收任务所需的数据。安全并不意味着实际收到了数据——它很可能位于系统缓冲区中。</li>
<li>阻塞发送可以是同步的，这意味着与接收任务发生握手以确认安全发送。</li>
<li>阻塞发送可以是异步的，如果一个系统缓冲区被用来保存数据，最终交付到接收。</li>
<li>阻塞接收只在数据已经到达之后，并且应用程序准备使用的时候“返回”。</li>
</ul>
</li>
<li><strong>非阻塞：</strong><ul>
<li>非阻塞发送和接收例程的行为类似——它们几乎会立即返回。它们不等待任何通信事件完成，比如消息从用户内存复制到系统缓冲区空间，或者消息的实际到达。</li>
<li>非阻塞操作只是“请求”MPI库在能够执行操作时执行该操作。用户无法预测何时会发生这种情况。</li>
<li>除非您知道请求的非阻塞操作实际上是由库执行的，否则修改应用程序缓冲区(变量空间)是不安全的。有一些“等待”的例程用来做这个。</li>
<li>非阻塞通信主要用于通信重叠计算和利用可能的性能增益。</li>
</ul>
</li>
</ul>
<table cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top">
<th>Blocking Send</th>
<th>Non-blocking Send</th>
</tr><tr valign="top">
<td width="50%"><pre>myvar = 0;

<p>for (i=1; i&lt;ntasks; i++) {<br>   task = i;<br>   <font color="#DF4442">MPI_Send (&amp;myvar … … task …);<br></font>   myvar = myvar + 2</p>
<p>   /* do some work */</p>
<p>   }</p>
<p></pre></td><td width="50%"><pre>myvar = 0;</p>
<p>for (i=1; i&lt;ntasks; i++) {<br>   task = i;<br>   <font color="#DF4442">MPI_Isend (&amp;myvar ... ... task ...);</font><br>   myvar = myvar + 2;</p>
<p>   /* do some work */</p>
<p>   <font color="#DF4442">MPI_Wait (...);</font><br>   }</p>
<p></pre></td></p>
</tr><tr valign="top">
<td align="center"><b>Safe.  Why?<b></b></b></td>
<td align="center"><b>Unsafe. Why?<b></b></b></td>
</tr></tbody></table>

<h4 id="顺序和公平"><a href="#顺序和公平" class="headerlink" title="顺序和公平"></a>顺序和公平</h4><ul>
<li><strong>顺序:</strong><ul>
<li>MPI保证消息不会相互超越。</li>
<li>如果发送方向同一目的地连续发送两条消息(消息1和消息2)，并且两者匹配相同的receive，则receive操作将在消息2之前接收消息1。</li>
<li>如果接收者连续发送了两个Receive (Receive 1和Receive 2)，并且两者都在寻找相同的消息，则Receive 1将在Receive 2之前接收该消息。</li>
<li>如果有多个线程参与通信操作，则顺序规则不适用。</li>
</ul>
</li>
<li><strong>公平：</strong><ul>
<li>MPI不能保证公平-它取决于程序员来防止“饥饿操作”。</li>
<li>示例:任务0向任务2发送一条消息。但是，task 1发送一个与task 2接收到的消息相匹配的竞争消息。只有一个发送将完成。</li>
</ul>
</li>
</ul>
<h3 id="MPI消息传递例程参数"><a href="#MPI消息传递例程参数" class="headerlink" title="MPI消息传递例程参数"></a>MPI消息传递例程参数</h3><p>MPI点对点通信例程通常具有采用以下格式之一的参数列表：</p>
<table width="90%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr><td bgcolor="#FOF5FE"><b>Blocking sends
    </b></td><td><tt><b><nobr>
    MPI_Send(buffer,count,type,dest,tag,comm) 
</nobr></b></tt></td></tr><tr><td bgcolor="#FOF5FE"><b>Non-blocking sends
    </b></td><td><tt><b><nobr>
    MPI_Isend(buffer,count,type,dest,tag,comm,request) 
</nobr></b></tt></td></tr><tr><td bgcolor="#FOF5FE"><b>Blocking receive
    </b></td><td><tt><b><nobr>
    MPI_Recv(buffer,count,type,source,tag,comm,status) 
</nobr></b></tt></td></tr><tr><td bgcolor="#FOF5FE"><b>Non-blocking receive
    </b></td><td><tt><b><nobr>
    MPI_Irecv(buffer,count,type,source,tag,comm,request) </nobr></b></tt></td>
</tr></tbody></table>

<h3 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h3><p>引用要发送或接收的数据的程序（应用程序）地址空间。 在大多数情况下，这只是发送/接收的变量名。 对于C程序，此参数通过引用传递，并且通常必须在前面加上一个＆符：＆var1</p>
<h3 id="Data-Count"><a href="#Data-Count" class="headerlink" title="Data Count"></a>Data Count</h3><p>指示要发送的特定类型的数据元素的数量。</p>
<h3 id="Data-Type"><a href="#Data-Type" class="headerlink" title="Data Type"></a>Data Type</h3><p>出于可移植性的考虑，MPI预定义了其基本数据类型。 下表列出了标准要求的那些内容。</p>
<table width="90%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr><th colspan="2">C Data Types</th>
    <th colspan="2">Fortran Data Types</th>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_CHAR</b></tt></td>
    <td>char</td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_CHARACTER</b></tt></td>
    <td>character(1)</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_WCHAR</b></tt></td>
    <td>wchar_t - wide character</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_SHORT</b></tt></td>
    <td>signed short int</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_INT</b></tt></td>
    <td>signed int</td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_INTEGER<br><font color="gray">MPI_INTEGER1
    <br>MPI_INTEGER2<br>MPI_INTEGER4</font></b></tt></td>
    <td>integer<br>integer*1<br>integer*2<br>integer*4</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_LONG</b></tt></td>
    <td>signed long int</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_LONG_LONG_INT
    <br>MPI_LONG_LONG</b></tt></td>
    <td>signed long long int</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_SIGNED_CHAR</b></tt></td>
    <td>signed char</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_UNSIGNED_CHAR</b></tt></td>
    <td>unsigned char</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_UNSIGNED_SHORT</b></tt></td>
    <td>unsigned short int</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_UNSIGNED</b></tt></td>
    <td>unsigned int</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_UNSIGNED_LONG</b></tt></td>
    <td>unsigned long int</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_UNSIGNED_LONG_LONG</b></tt></td>
    <td>unsigned long long int</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_FLOAT</b></tt></td>
    <td>float</td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_REAL<br><font color="gray">MPI_REAL2
    <br>MPI_REAL4<br>MPI_REAL8</font>
    </b></tt></td><td>real<br>real*2<br>real*4<br>real*8</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_DOUBLE</b></tt></td>
    <td>double</td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_DOUBLE_PRECISION</b></tt></td>
    <td>double precision</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_LONG_DOUBLE</b></tt></td>
    <td>long double</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_C_COMPLEX<br>MPI_C_FLOAT_COMPLEX</b></tt></td>
    <td>float _Complex</td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_COMPLEX</b></tt></td>
    <td>complex</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_C_DOUBLE_COMPLEX</b></tt></td>
    <td>double _Complex</td>
    <td bgcolor="#FOF5FE"><tt><b><font color="gray">MPI_DOUBLE_COMPLEX</font></b></tt></td>
    <td>double complex</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_C_LONG_DOUBLE_COMPLEX</b></tt></td>
    <td>long double _Complex</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_C_BOOL</b></tt></td>
    <td>_Bool</td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_LOGICAL</b></tt></td>
    <td>logical</td>

</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_INT8_T 
<br>MPI_INT16_T<br>MPI_INT32_T <br>MPI_INT64_T</b></tt></td>
    <td>int8_t<br>int16_t<br>int32_t <br>int64_t</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_UINT8_T 
<br>MPI_UINT16_T <br>MPI_UINT32_T <br>MPI_UINT64_T </b></tt></td>
    <td>uint8_t<br>uint16_t<br>uint32_t<br>uint64_t</td>
    <td bgcolor="#FOF5FE">&nbsp;</td>
    <td>&nbsp;</td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_BYTE</b></tt></td>
    <td>8 binary digits </td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_BYTE</b></tt></td>        
    <td>8 binary digits </td>
</tr><tr><td bgcolor="#FOF5FE"><tt><b>MPI_PACKED</b></tt></td>
    <td>data packed or unpacked with MPI_Pack()/
        MPI_Unpack</td>
    <td bgcolor="#FOF5FE"><tt><b>MPI_PACKED</b></tt></td>
    <td>data packed or unpacked with MPI_Pack()/
        MPI_Unpack</td>
</tr></tbody></table>

<p><strong>Notes:</strong></p>
<ul>
<li>程序员还可以创建自己的数据类型（请参阅<a href="https://computing.llnl.gov/tutorials/mpi/#Derived_Data_Types" target="_blank" rel="noopener">派生数据类型</a>）。</li>
<li>MPI_BYTE和MPI_PACKED与标准C或Fortran类型不对应。<li>Types shown in <font color="gray"><b>GRAY FONT</b></font> are recommended if
      possible.  
  </li></li>
<li>一些实现可能包括其他基本数据类型（MPI_LOGICAL2，MPI_COMPLEX32等）。 检查MPI头文件。</li>
</ul>
<h3 id="Destination"><a href="#Destination" class="headerlink" title="Destination"></a>Destination</h3><p>发送例程的参数，指示应在何处传递消息。 指定为接收进程的rank。</p>
<h3 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h3><p>接收例程的参数，指示消息的始发进程。 指定为发送进程的rank。 可以将其设置为通配符MPI_ANY_SOURCE，以接收来自任何任务的消息。</p>
<h3 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h3><p>程序员分配的用于标识消息的任意非负整数。 发送和接收操作应与消息标签匹配。 对于接收操作，通配符MPI_ANY_TAG可以用于接收任何消息，而不管其标签如何。 MPI标准保证可以将整数0-32767用作标记，但是大多数实现允许的范围远大于此范围。</p>
<h3 id="Communicator"><a href="#Communicator" class="headerlink" title="Communicator"></a>Communicator</h3><p>指示通信上下文或源或目标字段对其有效的进程集。 除非程序员明确创建新的通信器，否则通常使用预定义的通信器MPI_COMM_WORLD。</p>
<h3 id="Status"><a href="#Status" class="headerlink" title="Status"></a>Status</h3><p>对于接收操作，指示消息的来源和消息的标签。 在C语言中，此参数是指向预定义结构MPI_Status（例如stat.MPI_SOURCE stat.MPI_TAG）的指针。 在Fortran中，它是大小为MPI_STATUS_SIZE（例如stat（MPI_SOURCE）stat（MPI_TAG））的整数数组。 此外，可以通过MPI_Get_count例程从Status获得所接收的实际字节数。 如果稍后将查询消息的来源，标签或大小，则可以替换常量MPI_STATUS_IGNORE和MPI_STATUSES_IGNORE。</p>
<h3 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h3><p>由非阻塞发送和接收操作使用。 由于非阻塞操作可能会在获得请求的系统缓冲区空间之前返回，因此系统会发出唯一的“请求编号”。 程序员稍后（在WAIT类型的例程中）使用此系统分配的“句柄”来确定非阻塞操作的完成。 在C语言中，此参数是指向预定义结构MPI_Request的指针。 在Fortran中，它是整数。</p>
<h2 id="Blocking-Message-Passing-Routines"><a href="#Blocking-Message-Passing-Routines" class="headerlink" title="Blocking Message Passing Routines"></a>Blocking Message Passing Routines</h2><p>下面介绍了更常用的MPI阻塞消息传递例程。</p>
<h3 id="MPI-Send"><a href="#MPI-Send" class="headerlink" title="MPI_Send"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Send.txt" target="_blank" rel="noopener">MPI_Send</a></h3><p>基本阻塞发送操作。 例程仅在发送任务中的应用程序缓冲区可供重用之后才返回。 注意，该例程可以在不同的系统上以不同的方式实现。 MPI标准允许使用系统缓冲区，但不需要使用它。 一些实现可能实际上使用同步发送（在下面讨论）来实现基本的阻塞发送。</p>
<p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Send (&amp;buf,count,datatype,dest,tag,comm)  <br>
    MPI_SEND (buf,count,datatype,dest,tag,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>
</p>

<h3 id="MPI-Recv"><a href="#MPI-Recv" class="headerlink" title="MPI_Recv"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Recv.txt" target="_blank" rel="noopener">MPI_Recv</a></h3><p>接收消息并阻塞，直到接收任务中的应用程序缓冲区中有所需数据为止。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Recv (&amp;buf,count,datatype,source,tag,comm,&amp;status) <br> 
    MPI_RECV (buf,count,datatype,source,tag,comm,status,ierr) 
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Ssend"><a href="#MPI-Ssend" class="headerlink" title="MPI_Ssend "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Ssend.txt" target="_blank" rel="noopener">MPI_Ssend </a></h3><p>同步阻塞发送：发送消息并进行阻塞，直到发送任务中的应用程序缓冲区可供重新使用且目标进程已开始接收消息为止。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Ssend (&amp;buf,count,datatype,dest,tag,comm)  <br>
    MPI_SSEND (buf,count,datatype,dest,tag,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Sendrecv"><a href="#MPI-Sendrecv" class="headerlink" title="MPI_Sendrecv"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Sendrecv.txt" target="_blank" rel="noopener">MPI_Sendrecv</a></h3><p>在阻塞之前发送一个消息并发布一个接收。然后将一直阻塞直到发送应用程序缓冲区可以自由重用和接收应用程序缓冲区包含接收到的消息。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Sendrecv (&amp;sendbuf,sendcount,sendtype,dest,sendtag,  <br>
        <font color="#FFFFFF">......</font> 
                 &amp;recvbuf,recvcount,recvtype,source,recvtag,   <br>
        <font color="#FFFFFF">......</font> 
                 comm,&amp;status)   <br>
    MPI_SENDRECV (sendbuf,sendcount,sendtype,dest,sendtag,  <br> 
        <font color="#FFFFFF">......</font> 
                 recvbuf,recvcount,recvtype,source,recvtag,  <br>
        <font color="#FFFFFF">......</font> 
                 comm,status,ierr)
    </b></tt></nobr><p>
</p></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Wait"><a href="#MPI-Wait" class="headerlink" title="MPI_Wait"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Wait.txt" target="_blank" rel="noopener">MPI_Wait</a></h3><h3 id="MPI-Waitany"><a href="#MPI-Waitany" class="headerlink" title="MPI_Waitany"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Waitany.txt" target="_blank" rel="noopener">MPI_Waitany</a></h3><h3 id="MPI-Waitall"><a href="#MPI-Waitall" class="headerlink" title="MPI_Waitall"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Waitall.txt" target="_blank" rel="noopener">MPI_Waitall</a></h3><h3 id="MPI-Waitsome"><a href="#MPI-Waitsome" class="headerlink" title="MPI_Waitsome"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Waitsome.txt" target="_blank" rel="noopener">MPI_Waitsome</a></h3><p>MPI_Wait会阻塞，直到指定的非阻塞发送或接收操作完成为止。 对于多个非阻塞操作，程序员可以指定任何，全部或部分完成。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Wait     (&amp;request,&amp;status)  <br>
    MPI_Waitany  (count,&amp;array_of_requests,&amp;index,&amp;status)  <br>
    MPI_Waitall  (count,&amp;array_of_requests,&amp;array_of_statuses)  <br>
    MPI_Waitsome (incount,&amp;array_of_requests,&amp;outcount,  <br>
        <font color="#FFFFFF">......</font> 
        &amp;array_of_offsets, &amp;array_of_statuses)  <br>
    MPI_WAIT     (request,status,ierr)  <br>
    MPI_WAITANY  (count,array_of_requests,index,status,ierr)  <br>
    MPI_WAITALL  (count,array_of_requests,array_of_statuses,  <br>
        <font color="#FFFFFF">......</font> 
                 ierr)  <br>
    MPI_WAITSOME (incount,array_of_requests,outcount,  <br>
        <font color="#FFFFFF">......</font> 
                 array_of_offsets, array_of_statuses,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Probe"><a href="#MPI-Probe" class="headerlink" title="MPI_Probe"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Probe.txt" target="_blank" rel="noopener">MPI_Probe</a></h3><p>对消息执行阻止测试。 “通配符” MPI_ANY_SOURCE和MPI_ANY_TAG可用于测试来自任何来源或带有任何标签的消息。 对于C例程，实际的源和标签将在状态结构中作为status.MPI_SOURCE和status.MPI_TAG返回。 对于Fortran例程，它们将以整数数组status（MPI_SOURCE）和status（MPI_TAG）返回。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Probe (source,tag,comm,&amp;status)  <br>
    MPI_PROBE (source,tag,comm,status,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Get-count"><a href="#MPI-Get-count" class="headerlink" title="MPI_Get_count "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Get_count.txt" target="_blank" rel="noopener">MPI_Get_count </a></h3><p>返回接收到的数据类型的元素的来源，标签和数量。 可以与阻塞和非阻塞接收操作一起使用。 对于C例程，实际的源和标签将在状态结构中作为status.MPI_SOURCE和status.MPI_TAG返回。 对于Fortran例程，它们将以整数数组status（MPI_SOURCE）和status（MPI_TAG）返回。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Get_count (&amp;status,datatype,&amp;count)  <br>
    MPI_GET_COUNT (status,datatype,count,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h2 id="Examples-Blocking-Message-Passing-Routines"><a href="#Examples-Blocking-Message-Passing-Routines" class="headerlink" title="Examples: Blocking Message Passing Routines"></a>Examples: Blocking Message Passing Routines</h2><ul>
<p>
Task 0 pings task 1 and awaits return ping
</p><p>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Blocking Message Passing Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#df4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, dest, source, rc, count, tag=1;<br>   char inmsg, outmsg=’x’;<br>   <font color="#DF4442">MPI_Status Stat</font>;   <font color="#AAAAAA">// required variable for receive routines</font></p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);<br>   <font color="#DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);</p>
<p>   <font color="#AAAAAA">// task 0 sends to task 1 and waits to receive a return message</font><br>   if (rank == 0) {<br>     dest = 1;<br>     source = 1;<br>     <font color="#DF4442">MPI_Send</font>(&amp;outmsg, 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);<br>     <font color="#DF4442">MPI_Recv</font>(&amp;inmsg, 1, MPI_CHAR, source, tag, MPI_COMM_WORLD, &amp;Stat);<br>     } </p>
<p>   <font color="#AAAAAA">// task 1 waits for task 0 message then returns a message</font><br>   else if (rank == 1) {<br>     dest = 0;<br>     source = 0;<br>     <font color="#DF4442">MPI_Recv</font>(&amp;inmsg, 1, MPI_CHAR, source, tag, MPI_COMM_WORLD, &amp;Stat);<br>     <font color="#DF4442">MPI_Send</font>(&amp;outmsg, 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);<br>     }</p>
<p>   <font color="#AAAAAA">// query recieve Stat variable and print message details</font><br>   <font color="#DF4442">MPI_Get_count</font>(&amp;Stat, MPI_CHAR, &amp;count);<br>   printf(“Task %d: Received %d char(s) from task %d with tag %d \n”,<br>          rank, count, Stat.MPI_SOURCE, Stat.MPI_TAG);</p>
<p>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>  <!---outer table--->

<p><br><br><br></p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortran - Blocking Message Passing Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program ping
   include <font color="#DF4442">'mpif.h'</font>

<p>   integer numtasks, rank, dest, source, count, tag, ierr<br>   integer <font color="#DF4442">stat(MPI_STATUS_SIZE)</font>   <font color="#AAAAAA">! required variable for receive routines</font><br>   character inmsg, outmsg<br>   outmsg = ‘x’<br>   tag = 1</p>
<p>   call <font color="#DF4442">MPI_INIT</font>(ierr)<br>   call <font color="#DF4442">MPI_COMM_RANK</font>(MPI_COMM_WORLD, rank, ierr)<br>   call <font color="#DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   <font color="#AAAAAA">! task 0 sends to task 1 and waits to receive a return message</font><br>   if (rank .eq. 0) then<br>      dest = 1<br>      source = 1<br>      call <font color="#DF4442">MPI_SEND</font>(outmsg, 1, MPI_CHARACTER, dest, tag, MPI_COMM_WORLD, ierr)<br>      call <font color="#DF4442">MPI_RECV</font>(inmsg, 1, MPI_CHARACTER, source, tag, MPI_COMM_WORLD, stat, ierr)</p>
<p>   <font color="#AAAAAA">! task 1 waits for task 0 message then returns a message</font><br>   else if (rank .eq. 1) then<br>      dest = 0<br>      source = 0<br>      call <font color="#DF4442">MPI_RECV</font>(inmsg, 1, MPI_CHARACTER, source, tag, MPI_COMM_WORLD, stat, err)<br>      call <font color="#DF4442">MPI_SEND</font>(outmsg, 1, MPI_CHARACTER, dest, tag, MPI_COMM_WORLD, err)<br>   endif</p>
<p>   <font color="#AAAAAA">! query recieve Stat variable and print message details</font><br>   call <font color="#DF4442">MPI_GET_COUNT</font>(stat, MPI_CHARACTER, count, ierr)<br>   print *, ‘Task ‘,rank,’: Received’, count, ‘char(s) from task’, &amp;<br>            stat(MPI_SOURCE), ‘with tag’,stat(MPI_TAG)</p>
<p>   call <font color="#DF4442">MPI_FINALIZE</font>(ierr)</p>
<p>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>  <!---outer table--->
</p></ul>

<h2 id="非阻塞消息传递例程"><a href="#非阻塞消息传递例程" class="headerlink" title="非阻塞消息传递例程"></a>非阻塞消息传递例程</h2><p>下面描述了更常用的MPI非阻塞消息传递例程。</p>
<h3 id="MPI-Isend"><a href="#MPI-Isend" class="headerlink" title="MPI_Isend"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Isend.txt" target="_blank" rel="noopener">MPI_Isend</a></h3><p>标识内存中用作发送缓冲区的区域。程序立即继续进行，而不等待从应用程序缓冲区复制消息。返回一个通信请求句柄来处理挂起的消息状态。直到随后调用MPI_Wait或MPI_Test表明非阻塞发送已经完成,程序才可以修改应用程序缓冲区。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Isend (&amp;buf,count,datatype,dest,tag,comm,&amp;request) <br>
    MPI_ISEND (buf,count,datatype,dest,tag,comm,request,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Irecv"><a href="#MPI-Irecv" class="headerlink" title="MPI_Irecv"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Irecv.txt" target="_blank" rel="noopener">MPI_Irecv</a></h3><p>标识内存中用作接收缓冲区的区域。程序将立即继续，而无需实际等待消息被接收并复制到应用程序缓冲区中。返回一个通信请求句柄来处理挂起的消息状态。程序必须使用调用MPI_Wait或MPI_Test来确定非阻塞接收操作何时完成，请求的消息在应用程序缓冲区中可用。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Irecv (&amp;buf,count,datatype,source,tag,comm,&amp;request) <br>
    MPI_IRECV (buf,count,datatype,source,tag,comm,request,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Issend"><a href="#MPI-Issend" class="headerlink" title="MPI_Issend"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Issend.txt" target="_blank" rel="noopener">MPI_Issend</a></h3><p>非阻塞同步发送。与MPI_Isend()类似，除了MPI_Wait()或MPI_Test()表示目标进程何时收到消息。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Issend (&amp;buf,count,datatype,dest,tag,comm,&amp;request) <br>
    MPI_ISSEND (buf,count,datatype,dest,tag,comm,request,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Test"><a href="#MPI-Test" class="headerlink" title="MPI_Test"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Test.txt" target="_blank" rel="noopener">MPI_Test</a></h3><h3 id="MPI-Testany"><a href="#MPI-Testany" class="headerlink" title="MPI_Testany"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Testany.txt" target="_blank" rel="noopener">MPI_Testany</a></h3><h3 id="MPI-Testall"><a href="#MPI-Testall" class="headerlink" title="MPI_Testall"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Testall.txt" target="_blank" rel="noopener">MPI_Testall</a></h3><h3 id="MPI-Testsome"><a href="#MPI-Testsome" class="headerlink" title="MPI_Testsome"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Testsome.txt" target="_blank" rel="noopener">MPI_Testsome</a></h3><p>MPI测试检查指定的非阻塞发送或接收操作的状态。如果操作已经完成，“flag”参数将返回逻辑true(1)，如果没有，则返回逻辑false(0)。对于多个非阻塞操作，程序员可以指定任意、全部或部分补全。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Test     (&amp;request,&amp;flag,&amp;status) <br>
    MPI_Testany  (count,&amp;array_of_requests,&amp;index,&amp;flag,&amp;status)<br>
    MPI_Testall  (count,&amp;array_of_requests,&amp;flag,&amp;array_of_statuses)<br>
    MPI_Testsome (incount,&amp;array_of_requests,&amp;outcount,<br>
        <font color="#FFFFFF">......</font> 
                 &amp;array_of_offsets, &amp;array_of_statuses)<br>
    MPI_TEST     (request,flag,status,ierr)<br>
    MPI_TESTANY  (count,array_of_requests,index,flag,status,ierr)<br>
    MPI_TESTALL  (count,array_of_requests,flag,array_of_statuses,ierr)<br>
    MPI_TESTSOME (incount,array_of_requests,outcount,<br>
        <font color="#FFFFFF">......</font> 
                 array_of_offsets, array_of_statuses,ierr)<br>
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="MPI-Iprobe"><a href="#MPI-Iprobe" class="headerlink" title="MPI_Iprobe"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Iprobe.txt" target="_blank" rel="noopener">MPI_Iprobe</a></h3><p>对消息执行非阻塞测试。“通配符”MPI_ANY_SOURCE和MPI_ANY_TAG可以用于测试来自任何源或带有任何标记的消息。如果消息已经到达，那么整数“flag”参数将返回逻辑true(1)，如果没有到达，则返回逻辑false(0)。对于C例程，实际的源和标记将在状态结构中作为status返回MPI_SOURCE和status.MPI_TAG。对于Fortran例程，它们将以整数数组状态(MPI源)和状态(MPI标记)的形式返回。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Iprobe (source,tag,comm,&amp;flag,&amp;status)<br>
    MPI_IPROBE (source,tag,comm,flag,status,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="示例-非阻塞消息传递例程"><a href="#示例-非阻塞消息传递例程" class="headerlink" title="示例:非阻塞消息传递例程"></a>示例:非阻塞消息传递例程</h3><p>环拓扑中的最近邻交换</p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Non-blocking Message Passing Example</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, next, prev, buf[2], tag1=1, tag2=2;<br>   <font color="#DF4442">MPI_Request reqs[4]</font>;   <font color="#AAAAAA">// required variable for non-blocking calls</font><br>   <font color="#DF4442">MPI_Status stats[4]</font>;   <font color="#AAAAAA">// required variable for Waitall routine</font></p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);<br>   <font color="#DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);</p>
<p>   <font color="#AAAAAA">// determine left and right neighbors</font><br>   prev = rank-1;<br>   next = rank+1;<br>   if (rank == 0)  prev = numtasks - 1;<br>   if (rank == (numtasks - 1))  next = 0;</p>
<p>   <font color="#AAAAAA">// post non-blocking receives and sends for neighbors</font><br>   <font color="#DF4442">MPI_Irecv</font>(&amp;buf[0], 1, MPI_INT, prev, tag1, MPI_COMM_WORLD, &amp;reqs[0]);<br>   <font color="#DF4442">MPI_Irecv</font>(&amp;buf[1], 1, MPI_INT, next, tag2, MPI_COMM_WORLD, &amp;reqs[1]);</p>
<p>   <font color="#DF4442">MPI_Isend</font>(&amp;rank, 1, MPI_INT, prev, tag2, MPI_COMM_WORLD, &amp;reqs[2]);<br>   <font color="#DF4442">MPI_Isend</font>(&amp;rank, 1, MPI_INT, next, tag1, MPI_COMM_WORLD, &amp;reqs[3]);</p>
<p>   <font color="#AAAAAA">   // do some work while sends/receives progress in background</font></p>
<p>   <font color="#AAAAAA">// wait for all non-blocking operations to complete</font><br>   <font color="#DF4442">MPI_Waitall</font>(4, reqs, stats);</p>
<p>   <font color="#AAAAAA">   // continue - do more work</font></p>
<p>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<h2 id="集体通信例程"><a href="#集体通信例程" class="headerlink" title="集体通信例程"></a>集体通信例程</h2><h4 id="集体作业的类型"><a href="#集体作业的类型" class="headerlink" title="集体作业的类型"></a>集体作业的类型</h4><ul>
<li><strong>同步</strong>——进程等待，直到组中的所有成员都达到同步点。</li>
<li><strong>数据传送</strong>——广播(broadcast)，散布(scatter)和收集(gather),all to all. </li>
<li><strong>集合计算(归约)</strong>——组中的一个成员从其他成员那里收集数据，并对该数据执行操作(最小、最大、加、乘等)。</li>
</ul>
<h4 id="Scope"><a href="#Scope" class="headerlink" title="Scope:"></a>Scope:</h4><ul>
<li>集合通信例行程序必须包括通信者范围内的所有进程。<ul>
<li>默认情况下，所有进程都是通信器MPI_COMM_WORLD中的成员。</li>
<li>程序员可以定义其他通信器。有关详细信息，请参阅<a href="https://computing.llnl.gov/tutorials/mpi/#Group_Management_Routines" target="_blank" rel="noopener"> Group and Communicator Management Routines</a>部分。</li>
</ul>
</li>
<li>如果通信器中甚至有一个任务不参与，就可能发生意外的行为，包括程序失败。</li>
<li>确保通信器中的所有进程都参与到任何集体操作中是程序员的责任。</li>
</ul>
<h4 id="编程注意事项和限制"><a href="#编程注意事项和限制" class="headerlink" title="编程注意事项和限制"></a>编程注意事项和限制</h4><ul>
<li>集体通信例程不接受消息标签参数。</li>
<li>进程子集内的集体操作是通过首先将子集划分为新组，然后将新组附加到新通信器来完成的((discussed in the <a href="https://computing.llnl.gov/tutorials/mpi/#Group_Management_Routines" target="_blank" rel="noopener">Group and Communicator Management Routines</a> section). )</li>
<li>只能与MPI预定义的数据类型一起使用——而不能与MPI<a href="https://computing.llnl.gov/tutorials/mpi/#Derived_Data_Types" target="_blank" rel="noopener">派生的数据类型</a>一起使用。</li>
<li>MPI-2扩展了大多数集合操作，允许在通信器之间移动数据(这里没有介绍)。</li>
<li>对于MPI-3，集合操作可以是阻塞的，也可以是非阻塞的。本教程只介绍阻塞操作。</li>
</ul>
<h3 id="集合通信例程"><a href="#集合通信例程" class="headerlink" title="集合通信例程"></a>集合通信例程</h3><h4 id="MPI-Barrier"><a href="#MPI-Barrier" class="headerlink" title="MPI_Barrier"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Barrier.txt" target="_blank" rel="noopener">MPI_Barrier</a></h4><p>同步操作。在组中创建barrier同步。每个任务在到达MPI_Barrier调用时都会阻塞，直到组中的所有任务都到达相同的MPI_Barrier调用为止。然后所有的任务都可以继续进行。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Barrier (comm)<br>
    MPI_BARRIER (comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Bcast"><a href="#MPI-Bcast" class="headerlink" title="MPI_Bcast"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Bcast.txt" target="_blank" rel="noopener">MPI_Bcast</a></h4><p>数据移动操作。从rank为“root”的进程向组中的所有其他进程广播(发送)消息。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Bcast (&amp;buffer,count,datatype,root,comm)   <br>
    MPI_BCAST (buffer,count,datatype,root,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Scatter"><a href="#MPI-Scatter" class="headerlink" title="MPI_Scatter"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Scatter.txt" target="_blank" rel="noopener">MPI_Scatter</a></h4><p>数据移动操作。将来自单个源任务的不同消息分发到组中的每个任务。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Scatter (&amp;sendbuf,sendcnt,sendtype,&amp;recvbuf,   <br>
        <font color="#FFFFFF">......</font> 
                recvcnt,recvtype,root,comm)  <br>
    MPI_SCATTER (sendbuf,sendcnt,sendtype,recvbuf,  <br> 
        <font color="#FFFFFF">......</font> 
                recvcnt,recvtype,root,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Gather"><a href="#MPI-Gather" class="headerlink" title="MPI_Gather"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Gather.txt" target="_blank" rel="noopener">MPI_Gather</a></h4><p>数据移动操作。将组中每个任务的不同消息收集到单个目标任务。这个例程是MPI_Scatter的反向操作。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Gather (&amp;sendbuf,sendcnt,sendtype,&amp;recvbuf,  <br>
        <font color="#FFFFFF">......</font> 
               recvcount,recvtype,root,comm)  <br>
    MPI_GATHER (sendbuf,sendcnt,sendtype,recvbuf,  <br>
        <font color="#FFFFFF">......</font> 
               recvcount,recvtype,root,comm,ierr)  
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Allgather"><a href="#MPI-Allgather" class="headerlink" title="MPI_Allgather"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Allgather.txt" target="_blank" rel="noopener">MPI_Allgather</a></h4><p>数据移动操作。数据与组中所有任务的连接。组中的每个任务实际上在组内执行一对所有的广播操作。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Allgather (&amp;sendbuf,sendcount,sendtype,&amp;recvbuf,  <br>
        <font color="#FFFFFF">......</font> 
                  recvcount,recvtype,comm) <br>
    MPI_ALLGATHER (sendbuf,sendcount,sendtype,recvbuf, <br> 
        <font color="#FFFFFF">......</font> 
                  recvcount,recvtype,comm,info)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Reduce"><a href="#MPI-Reduce" class="headerlink" title=" MPI_Reduce "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Reduce.txt" target="_blank" rel="noopener"> MPI_Reduce </a></h4><p>集体计算操作。对组中的所有任务应用reduce操作，并将结果放在一个任务中。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Reduce (&amp;sendbuf,&amp;recvbuf,count,datatype,op,root,comm) <br>
    MPI_REDUCE (sendbuf,recvbuf,count,datatype,op,root,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<p>下面显示了预定义的MPI精简操作。用户还可以使用<a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Op_create.txt" target="_blank" rel="noopener">MPI_Op_create</a>例程定义自己的reduce函数。</p>
<table width="90%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="TOP">
<th colspan="2">MPI Reduction Operation</th> 
<th>C Data Types</th>
<th>Fortran Data Type</th>
</tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b> MPI_MAX    
</b></tt></td><td>maximum       
</td><td>integer, float      
</td><td>integer, real, complex  
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_MIN    
</b></tt></td><td>minimum       
</td><td>integer, float      
</td><td>integer, real, complex  
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_SUM    
</b></tt></td><td>sum          
</td><td>integer, float      
</td><td>integer, real, complex  
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_PROD    
</b></tt></td><td>product      
</td><td>integer, float      
</td><td>integer, real, complex  
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_LAND    
</b></tt></td><td>logical AND   
</td><td>integer           
</td><td>logical                 
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_BAND    
</b></tt></td><td>bit-wise AND  
</td><td>integer, MPI_BYTE   
</td><td>integer, MPI_BYTE      
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_LOR    
</b></tt></td><td>logical OR    
</td><td>integer            
</td><td>logical                 
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_BOR    
</b></tt></td><td>bit-wise OR   
</td><td>integer, MPI_BYTE   
</td><td>integer, MPI_BYTE       
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_LXOR    
</b></tt></td><td>logical XOR   
</td><td>integer           
</td><td>logical                 
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_BXOR    
</b></tt></td><td>bit-wise XOR  
</td><td>integer, MPI_BYTE   
</td><td>integer, MPI_BYTE      
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_MAXLOC  
</b></tt></td><td>max value and location
</td><td>float, double and long double         
</td><td>real, complex,double precision        
</td></tr><tr valign="TOP">
<td bgcolor="#FOF5FE"><tt><b>MPI_MINLOC  
</b></tt></td><td>min value and location 
</td><td>float, double and long double         
</td><td>real, complex, double precision        
</td></tr></tbody></table>

<ul>
<li>MPI_Reduce手册页中的说明:操作总是被假定为关联的。所有预定义的操作都假定是可交换的。用户可以定义被假定为关联而非交换的操作。归约的“规范”评估顺序由组中进程的rank决定。但是，实现可以利用结合性，或者结合性和交换性来改变计算顺序。这可能会改变非严格结合性和可交换性操作(如浮点加法)的归约结果。强烈建议实现MPI_REDUCE，以便当函数被应用到相同的参数上时，以相同的顺序出现时，可以获得相同的结果。注意，这可能会阻止优化利用处理器的物理位置。</li>
</ul>
<h4 id="MPI-Allreduce"><a href="#MPI-Allreduce" class="headerlink" title=" MPI_Allreduce "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Allreduce.txt" target="_blank" rel="noopener"> MPI_Allreduce </a></h4><p>集体计算操作+数据移动。应用归约操作并将结果放置到组中的所有任务中。这相当于MPI_Reduce后再进行MPI_Bcast。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Allreduce (&amp;sendbuf,&amp;recvbuf,count,datatype,op,comm) <br>
    MPI_ALLREDUCE (sendbuf,recvbuf,count,datatype,op,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Reduce-scatter"><a href="#MPI-Reduce-scatter" class="headerlink" title=" MPI_Reduce_scatter "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Reduce_scatter.txt" target="_blank" rel="noopener"> MPI_Reduce_scatter </a></h4><p>集体计算操作+数据移动。首先对组中所有任务的向量进行element-wise的归约。接下来，结果向量被分割成不相交的片段并分布在各个任务中。这相当于在MPI_Reduce之后执行MPI_Scatter操作。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Reduce_scatter (&amp;sendbuf,&amp;recvbuf,recvcount,datatype, <br>
        <font color="#FFFFFF">......</font>
         op,comm) <br>
    MPI_REDUCE_SCATTER (sendbuf,recvbuf,recvcount,datatype, <br>
        <font color="#FFFFFF">......</font>
         op,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Alltoall"><a href="#MPI-Alltoall" class="headerlink" title=" MPI_Alltoall "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Alltoall.txt" target="_blank" rel="noopener"> MPI_Alltoall </a></h4><p>数据移动操作。组中的每个任务执行scatter操作，按照索引的顺序向组中的所有任务发送不同的消息。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Alltoall (&amp;sendbuf,sendcount,sendtype,&amp;recvbuf, <br>
        <font color="#FFFFFF">......</font>
                 recvcnt,recvtype,comm) <br>
    MPI_ALLTOALL (sendbuf,sendcount,sendtype,recvbuf, <br>
        <font color="#FFFFFF">......</font>
                 recvcnt,recvtype,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Scan"><a href="#MPI-Scan" class="headerlink" title=" MPI_Scan "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Scan.txt" target="_blank" rel="noopener"> MPI_Scan </a></h4><p>对整个任务组的归约操作执行扫描操作。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Scan (&amp;sendbuf,&amp;recvbuf,count,datatype,op,comm) <br>
    MPI_SCAN (sendbuf,recvbuf,count,datatype,op,comm,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="例子-集体通信"><a href="#例子-集体通信" class="headerlink" title="例子:集体通信"></a>例子:集体通信</h3><p>对数组的行执行分散操作</p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Collective Communications Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;
   #define SIZE 4

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, sendcount, recvcount, source;<br>   float sendbuf[SIZE][SIZE] = {<br>     {1.0, 2.0, 3.0, 4.0},<br>     {5.0, 6.0, 7.0, 8.0},<br>     {9.0, 10.0, 11.0, 12.0},<br>     {13.0, 14.0, 15.0, 16.0}  };<br>   float recvbuf[SIZE];</p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);</p>
<p>   if (numtasks == SIZE) {<br>     <font color="#AAAAAA">// define source task and elements to send/receive, then perform collective scatter</font><br>     source = 1;<br>     sendcount = SIZE;<br>     recvcount = SIZE;<br>     <font color="#DF4442">MPI_Scatter</font>(sendbuf,sendcount,MPI_FLOAT,recvbuf,recvcount,<br>                 MPI_FLOAT,source,MPI_COMM_WORLD);</p>
<pre><code>printf(&quot;rank= %d  Results: %f %f %f %f\n&quot;,rank,recvbuf[0],
       recvbuf[1],recvbuf[2],recvbuf[3]);
}</code></pre><p>   else<br>     printf(“Must specify %d processors. Terminating.\n”,SIZE);</p>
<p>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortran - Collective Communications Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program scatter
   include <font color="#DF4442">'mpif.h'</font>

<p>   integer SIZE<br>   parameter(SIZE=4)<br>   integer numtasks, rank, sendcount, recvcount, source, ierr<br>   real*4 sendbuf(SIZE,SIZE), recvbuf(SIZE)</p>
<p>   <font color="#AAAAAA">! Fortran stores this array in column major order, so the<br>   ! scatter will actually scatter columns, not rows.</font><br>   data sendbuf /1.0, 2.0, 3.0, 4.0, &amp;<br>                 5.0, 6.0, 7.0, 8.0, &amp;<br>                 9.0, 10.0, 11.0, 12.0, &amp;<br>                 13.0, 14.0, 15.0, 16.0 /</p>
<p>   call <font color="#DF4442">MPI_INIT</font>(ierr)<br>   call <font color="#DF4442">MPI_COMM_RANK</font>(MPI_COMM_WORLD, rank, ierr)<br>   call <font color="#DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   if (numtasks .eq. SIZE) then<br>      <font color="#AAAAAA">! define source task and elements to send/receive, then perform collective scatter</font><br>      source = 1<br>      sendcount = SIZE<br>      recvcount = SIZE<br>      call <font color="#DF4442">MPI_SCATTER</font>(sendbuf, sendcount, MPI_REAL, recvbuf, recvcount, MPI_REAL, &amp;<br>                       source, MPI_COMM_WORLD, ierr)</p>
<pre><code>print *, &apos;rank= &apos;,rank,&apos; Results: &apos;,recvbuf </code></pre><p>   else<br>      print *, ‘Must specify’,SIZE,’ processors.  Terminating.’<br>   endif</p>
<p>   call <font color="#DF4442">MPI_FINALIZE</font>(ierr)</p>
<p>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<h2 id="派生数据类型"><a href="#派生数据类型" class="headerlink" title="派生数据类型"></a>派生数据类型</h2><ul>
<li>如前所述，MPI预定义了它的基本数据类型</li>
</ul>
<table width="90%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr><th colspan="2">C Data Types</th>
<th>Fortran Data Types</th>
</tr><tr valign="top">
<td width="33%"><pre>MPI_CHAR
MPI_WCHAR
MPI_SHORT
MPI_INT
MPI_LONG
MPI_LONG_LONG_INT 
MPI_LONG_LONG          
MPI_SIGNED_CHAR
MPI_UNSIGNED_CHAR
MPI_UNSIGNED_SHORT
MPI_UNSIGNED_LONG
MPI_UNSIGNED
MPI_FLOAT
MPI_DOUBLE
MPI_LONG_DOUBLE
</pre></td>
<td width="33%"><pre>MPI_C_COMPLEX
MPI_C_FLOAT_COMPLEX
MPI_C_DOUBLE_COMPLEX
MPI_C_LONG_DOUBLE_COMPLEX          
MPI_C_BOOL
MPI_LOGICAL
MPI_C_LONG_DOUBLE_COMPLEX      
MPI_INT8_T 
MPI_INT16_T
MPI_INT32_T 
MPI_INT64_T          
MPI_UINT8_T 
MPI_UINT16_T 
MPI_UINT32_T 
MPI_UINT64_T
MPI_BYTE
MPI_PACKED
</pre></td>
<td width="33%"><pre>MPI_CHARACTER
MPI_INTEGER
MPI_INTEGER1 
MPI_INTEGER2
MPI_INTEGER4
MPI_REAL
MPI_REAL2 
MPI_REAL4
MPI_REAL8
MPI_DOUBLE_PRECISION
MPI_COMPLEX
MPI_DOUBLE_COMPLEX
MPI_LOGICAL
MPI_BYTE
MPI_PACKED
</pre></td>
</tr></tbody></table>

<ul>
<li>MPI还提供了根据MPI基本数据类型序列定义自己的数据结构的工具。这种用户定义的结构称为派生数据类型。</li>
<li>基本数据类型是连续的。派生数据类型允许您以方便的方式指定非连续数据，并将其视为连续数据。</li>
<li>MPI提供了几种构造派生数据类型的方法<ul>
<li>连续的（Contiguous）</li>
<li>向量（Vector）</li>
<li>Indexed</li>
<li>Struct</li>
</ul>
</li>
</ul>
<h3 id="派生数据类型例程"><a href="#派生数据类型例程" class="headerlink" title="派生数据类型例程"></a>派生数据类型例程</h3><h4 id="MPI-Type-contiguous"><a href="#MPI-Type-contiguous" class="headerlink" title=" MPI_Type_contiguous"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_contiguous.txt" target="_blank" rel="noopener"> MPI_Type_contiguous</a></h4><p>最简单的构造函数。通过对现有数据类型进行计数复制，生成新的数据类型。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Type_contiguous (count,oldtype,&amp;newtype) <br>
    MPI_TYPE_CONTIGUOUS (count,oldtype,newtype,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Type-vector"><a href="#MPI-Type-vector" class="headerlink" title="MPI_Type_vector"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_vector.txt" target="_blank" rel="noopener">MPI_Type_vector</a></h4><h4 id="MPI-Type-hvector"><a href="#MPI-Type-hvector" class="headerlink" title="MPI_Type_hvector"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_hvector.txt" target="_blank" rel="noopener">MPI_Type_hvector</a></h4><p>类似于连续，但允许在位移中有规则的间隙(stride)。MPI_Type_hvector与MPI_Type_vector相同，不同的是跨步是以字节为单位指定的。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Type_vector (count,blocklength,stride,oldtype,&amp;newtype)<br> 
    MPI_TYPE_VECTOR (count,blocklength,stride,oldtype,newtype,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Type-indexed"><a href="#MPI-Type-indexed" class="headerlink" title="MPI_Type_indexed"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_indexed.txt" target="_blank" rel="noopener">MPI_Type_indexed</a></h4><h4 id="MPI-Type-hindexed"><a href="#MPI-Type-hindexed" class="headerlink" title=" MPI_Type_hindexed "></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_hindexed.txt" target="_blank" rel="noopener"> MPI_Type_hindexed </a></h4><p>提供输入数据类型的位移数组作为新数据类型的映射。MPI_Type_hindexed与MPI_Type_indexed是相同的，除了偏移量是用字节指定的。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Type_indexed (count,blocklens[],offsets[],old_type,&amp;newtype)<br>
    MPI_TYPE_INDEXED (count,blocklens(),offsets(),old_type,newtype,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Type-struct"><a href="#MPI-Type-struct" class="headerlink" title="MPI_Type_struct"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_struct.txt" target="_blank" rel="noopener">MPI_Type_struct</a></h4><p>新的数据类型是根据组件数据类型的完全定义映射形成的。</p>
<p><strong>NOTE:</strong> 该函数在MPI-2.0中不提倡使用，在MPI-3.0中被MPI_Type_creat_struct替代</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Type_struct (count,blocklens[],offsets[],old_types,&amp;newtype)<br>
    MPI_TYPE_STRUCT (count,blocklens(),offsets(),old_types,newtype,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Type-extent"><a href="#MPI-Type-extent" class="headerlink" title="MPI_Type_extent"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_extent.txt" target="_blank" rel="noopener">MPI_Type_extent</a></h4><p>返回指定数据类型的大小(以字节为单位)。对于需要指定字节偏移量的MPI子例程很有用。</p>
<p><strong>NOTE:</strong> 该函数在MPI-2.0中不赞成使用，在MPI-3.0中被MPI_Type_get_extent替换</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Type_extent (datatype,&amp;extent)<br>
    MPI_TYPE_EXTENT (datatype,extent,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Type-commit"><a href="#MPI-Type-commit" class="headerlink" title="MPI_Type_commit"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_commit.txt" target="_blank" rel="noopener">MPI_Type_commit</a></h4><p>向系统提交新的数据类型。所有用户构造(派生)数据类型都需要。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Type_commit (&amp;datatype)<br>
    MPI_TYPE_COMMIT (datatype,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h4 id="MPI-Type-free"><a href="#MPI-Type-free" class="headerlink" title="MPI_Type_free"></a><a href="https://computing.llnl.gov/tutorials/mpi/man/MPI_Type_free.txt" target="_blank" rel="noopener">MPI_Type_free</a></h4><p>释放指定的数据类型对象。如果在循环中创建了许多数据类型对象，那么使用这个例程对于防止内存耗尽尤其重要。</p>
<table width="75%" cellspacing="0" cellpadding="5" border="1">
<tbody><tr valign="top"><td><nobr><tt><b> 
    MPI_Type_free (&amp;datatype)<br>
    MPI_TYPE_FREE (datatype,ierr)
</b></tt></nobr></td></tr><tr></tr></tbody></table>

<h3 id="示例-连续派生数据类型"><a href="#示例-连续派生数据类型" class="headerlink" title="示例:连续派生数据类型"></a>示例:连续派生数据类型</h3><p>创建表示数组中的一行的数据类型，并将另一行分发给所有进程。</p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Contiguous Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;
   #define SIZE 4

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, source=0, dest, tag=1, i;<br>   float a[SIZE][SIZE] =<br>     {1.0, 2.0, 3.0, 4.0,<br>      5.0, 6.0, 7.0, 8.0,<br>      9.0, 10.0, 11.0, 12.0,<br>      13.0, 14.0, 15.0, 16.0};<br>   float b[SIZE];</p>
<p>   <font color="#DF4442">MPI_Status stat</font>;<br>   <font color="#DF4442">MPI_Datatype rowtype</font>;   <font color="#AAAAAA">// required variable</font></p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);</p>
<p>   <font color="#AAAAAA">// create contiguous derived data type</font><br>   <font color="#DF4442">MPI_Type_contiguous</font>(SIZE, MPI_FLOAT, &amp;rowtype);<br>   <font color="#DF4442">MPI_Type_commit</font>(&amp;rowtype);</p>
<p>   if (numtasks == SIZE) {<br>      <font color="#AAAAAA">// task 0 sends one element of rowtype to all tasks</font><br>      if (rank == 0) {<br>         for (i=0; i&lt;numtasks; i++)<br>           <font color="#DF4442">MPI_Send</font>(&amp;a[i][0], 1, rowtype, i, tag, MPI_COMM_WORLD);<br>         }</p>
<pre><code>&lt;font color=&quot;#AAAAAA&quot;&gt;// all tasks receive rowtype data from task 0&lt;/font&gt;
&lt;font color=&quot;#DF4442&quot;&gt;MPI_Recv&lt;/font&gt;(b, SIZE, MPI_FLOAT, source, tag, MPI_COMM_WORLD, &amp;amp;stat);
printf(&quot;rank= %d  b= %3.1f %3.1f %3.1f %3.1f\n&quot;,
       rank,b[0],b[1],b[2],b[3]);
}</code></pre><p>   else<br>      printf(“Must specify %d processors. Terminating.\n”,SIZE);</p>
<p>   <font color="#AAAAAA">// free datatype when done using it</font><br>   <font color="#DF4442">MPI_Type_free</font>(&amp;rowtype);<br>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortran - Contiguous Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program contiguous
   include <font color="#DF4442">'mpif.h'</font>

<p>   integer SIZE<br>   parameter(SIZE=4)<br>   integer numtasks, rank, source, dest, tag, i,  ierr<br>   real*4 a(0:SIZE-1,0:SIZE-1), b(0:SIZE-1)<br>   integer <font color="#DF4442">stat(MPI_STATUS_SIZE)</font><br>   integer <font color="#DF4442">columntype</font>   <font color="#AAAAAA">! required variable</font><br>   tag = 1</p>
<p>   <font color="#AAAAAA">! Fortran stores this array in column major order</font><br>   data a  /1.0, 2.0, 3.0, 4.0, &amp;<br>            5.0, 6.0, 7.0, 8.0, &amp;<br>            9.0, 10.0, 11.0, 12.0, &amp;<br>            13.0, 14.0, 15.0, 16.0 /</p>
<p>   call <font color="#DF4442">MPI_INIT</font>(ierr)<br>   call <font color="#DF4442">MPI_COMM_RANK</font>(MPI_COMM_WORLD, rank, ierr)<br>   call <font color="#DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   <font color="#AAAAAA">! create contiguous derived data type</font><br>   call <font color="#DF4442">MPI_TYPE_CONTIGUOUS</font>(SIZE, MPI_REAL, columntype, ierr)<br>   call <font color="#DF4442">MPI_TYPE_COMMIT</font>(columntype, ierr)</p>
<p>   if (numtasks .eq. SIZE) then<br>      <font color="#AAAAAA">! task 0 sends one element of columntype to all tasks</font><br>      if (rank .eq. 0) then<br>         do i=0, numtasks-1<br>         call <font color="#DF4442">MPI_SEND</font>(a(0,i), 1, columntype, i, tag, MPI_COMM_WORLD,ierr)<br>         end do<br>      endif</p>
<pre><code>&lt;font color=&quot;#AAAAAA&quot;&gt;! all tasks receive columntype data from task 0&lt;/font&gt;
source = 0
call &lt;font color=&quot;#DF4442&quot;&gt;MPI_RECV&lt;/font&gt;(b, SIZE, MPI_REAL, source, tag, MPI_COMM_WORLD, stat, ierr)
print *, &apos;rank= &apos;,rank,&apos; b= &apos;,b</code></pre><p>   else<br>      print *, ‘Must specify’,SIZE,’ processors.  Terminating.’<br>   endif</p>
<p>   <font color="#AAAAAA">! free datatype when done using it</font><br>   call <font color="#DF4442">MPI_TYPE_FREE</font>(columntype, ierr)<br>   call <font color="#DF4442">MPI_FINALIZE</font>(ierr)</p>
<p>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<p> Sample program output: </p>
 <pre>rank= 0  b= 1.0 2.0 3.0 4.0
rank= 1  b= 5.0 6.0 7.0 8.0
rank= 2  b= 9.0 10.0 11.0 12.0
rank= 3  b= 13.0 14.0 15.0 16.0
</pre>

<h3 id="示例-向量派生的数据类型"><a href="#示例-向量派生的数据类型" class="headerlink" title="示例:向量派生的数据类型"></a>示例:向量派生的数据类型</h3><p>创建表示数组中的列的数据类型，并将不同的列分发给所有进程。</p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Vector Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;
   #define SIZE 4

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, source=0, dest, tag=1, i;<br>   float a[SIZE][SIZE] =<br>     {1.0, 2.0, 3.0, 4.0,<br>      5.0, 6.0, 7.0, 8.0,<br>      9.0, 10.0, 11.0, 12.0,<br>     13.0, 14.0, 15.0, 16.0};<br>   float b[SIZE]; </p>
<p>   <font color="#DF4442">MPI_Status stat</font>;<br>   <font color="#DF4442">MPI_Datatype columntype</font>;   <font color="#AAAAAA">// required variable</font></p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);</p>
<p>   <font color="#AAAAAA">// create vector derived data type</font><br>   <font color="#DF4442">MPI_Type_vector</font>(SIZE, 1, SIZE, MPI_FLOAT, &amp;columntype);<br>   <font color="#DF4442">MPI_Type_commit</font>(&amp;columntype);</p>
<p>   if (numtasks == SIZE) {<br>      <font color="#AAAAAA">// task 0 sends one element of columntype to all tasks</font><br>      if (rank == 0) {<br>         for (i=0; i&lt;numtasks; i++)<br>            <font color="#DF4442">MPI_Send</font>(&amp;a[0][i], 1, columntype, i, tag, MPI_COMM_WORLD);<br>         }</p>
<pre><code>&lt;font color=&quot;#AAAAAA&quot;&gt;// all tasks receive columntype data from task 0&lt;/font&gt;
&lt;font color=&quot;#DF4442&quot;&gt;MPI_Recv&lt;/font&gt;(b, SIZE, MPI_FLOAT, source, tag, MPI_COMM_WORLD, &amp;amp;stat);
printf(&quot;rank= %d  b= %3.1f %3.1f %3.1f %3.1f\n&quot;,
       rank,b[0],b[1],b[2],b[3]);
}</code></pre><p>   else<br>      printf(“Must specify %d processors. Terminating.\n”,SIZE);</p>
<p>   <font color="#AAAAAA">// free datatype when done using it</font><br>   <font color="#DF4442">MPI_Type_free</font>(&amp;columntype);<br>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortran - Vector Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program vector
   include <font color="#DF4442">'mpif.h'</font>

<p>   integer SIZE<br>   parameter(SIZE=4)<br>   integer numtasks, rank, source, dest, tag, i,  ierr<br>   real*4 a(0:SIZE-1,0:SIZE-1), b(0:SIZE-1)<br>   integer <font color="#DF4442">stat(MPI_STATUS_SIZE)</font><br>   integer <font color="#DF4442">rowtype</font>   <font color="#AAAAAA">! required variable</font><br>   tag = 1</p>
<p>   <font color="#AAAAAA">! Fortran stores this array in column major order</font><br>   data a  /1.0, 2.0, 3.0, 4.0, &amp;<br>            5.0, 6.0, 7.0, 8.0,  &amp;<br>            9.0, 10.0, 11.0, 12.0, &amp;<br>            13.0, 14.0, 15.0, 16.0 /</p>
<p>   call <font color="#DF4442">MPI_INIT</font>(ierr)<br>   call <font color="#DF4442">MPI_COMM_RANK</font>(MPI_COMM_WORLD, rank, ierr)<br>   call <font color="#DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   <font color="#AAAAAA">! create vector derived data type</font><br>   call <font color="#DF4442">MPI_TYPE_VECTOR</font>(SIZE, 1, SIZE, MPI_REAL, rowtype, ierr)<br>   call <font color="#DF4442">MPI_TYPE_COMMIT</font>(rowtype, ierr)</p>
<p>   if (numtasks .eq. SIZE) then<br>      <font color="#AAAAAA">! task 0 sends one element of rowtype to all tasks</font><br>      if (rank .eq. 0) then<br>         do i=0, numtasks-1<br>         call <font color="#DF4442">MPI_SEND</font>(a(i,0), 1, rowtype, i, tag, MPI_COMM_WORLD, ierr)<br>         end do<br>      endif</p>
<pre><code>&lt;font color=&quot;#AAAAAA&quot;&gt;! all tasks receive rowtype data from task 0&lt;/font&gt;
source = 0
call &lt;font color=&quot;#DF4442&quot;&gt;MPI_RECV&lt;/font&gt;(b, SIZE, MPI_REAL, source, tag, MPI_COMM_WORLD, stat, ierr)
print *, &apos;rank= &apos;,rank,&apos; b= &apos;,b</code></pre><p>   else<br>      print *, ‘Must specify’,SIZE,’ processors.  Terminating.’<br>   endif</p>
<p>   <font color="#AAAAAA">! free datatype when done using it</font><br>   call <font color="#DF4442">MPI_TYPE_FREE</font>(rowtype, ierr)<br>   call <font color="#DF4442">MPI_FINALIZE</font>(ierr)</p>
<p>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<p> Sample program output: </p>
 <pre>rank= 0  b= 1.0 5.0 9.0 13.0
rank= 1  b= 2.0 6.0 10.0 14.0
rank= 2  b= 3.0 7.0 11.0 15.0
rank= 3  b= 4.0 8.0 12.0 16.0
</pre>

<h3 id="示例-索引派生数据类型"><a href="#示例-索引派生数据类型" class="headerlink" title="示例:索引派生数据类型"></a>示例:索引派生数据类型</h3><p>通过提取数组的可变部分来创建数据类型并分发给所有任务。</p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Indexed Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;
   #define NELEMENTS 6

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, source=0, dest, tag=1, i;<br>   int blocklengths[2], displacements[2];<br>   float a[16] =<br>     {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0,<br>      9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};<br>   float b[NELEMENTS]; </p>
<p>   <font color="#DF4442">MPI_Status stat</font>;<br>   <font color="#DF4442">MPI_Datatype indextype</font>;   <font color="#AAAAAA">// required variable</font></p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);</p>
<p>   blocklengths[0] = 4;<br>   blocklengths[1] = 2;<br>   displacements[0] = 5;<br>   displacements[1] = 12;</p>
<p>   <font color="#AAAAAA">// create indexed derived data type</font><br>   <font color="#DF4442">MPI_Type_indexed</font>(2, blocklengths, displacements, MPI_FLOAT, &amp;indextype);<br>   <font color="#DF4442">MPI_Type_commit</font>(&amp;indextype);</p>
<p>   if (rank == 0) {<br>     for (i=0; i&lt;numtasks; i++)<br>      <font color="#AAAAAA">// task 0 sends one element of indextype to all tasks</font><br>        <font color="#DF4442">MPI_Send</font>(a, 1, indextype, i, tag, MPI_COMM_WORLD);<br>     }</p>
<p>   <font color="#AAAAAA">// all tasks receive indextype data from task 0</font><br>   <font color="#DF4442">MPI_Recv</font>(b, NELEMENTS, MPI_FLOAT, source, tag, MPI_COMM_WORLD, &amp;stat);<br>   printf(“rank= %d  b= %3.1f %3.1f %3.1f %3.1f %3.1f %3.1f\n”,<br>          rank,b[0],b[1],b[2],b[3],b[4],b[5]);</p>
<p>   <font color="#AAAAAA">// free datatype when done using it</font><br>   <font color="#DF4442">MPI_Type_free</font>(&amp;indextype);<br>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortran - Indexed Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program indexed
   include <font color="#DF4442">'mpif.h'</font>

<p>   integer NELEMENTS<br>   parameter(NELEMENTS=6)<br>   integer numtasks, rank, source, dest, tag, i,  ierr<br>   integer blocklengths(0:1), displacements(0:1)<br>   real*4 a(0:15), b(0:NELEMENTS-1)<br>   integer <font color="#DF4442">stat(MPI_STATUS_SIZE)</font><br>   integer <font color="#DF4442">indextype</font>   <font color="#AAAAAA">! required variable</font><br>   tag = 1</p>
<p>   data a  /1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, &amp;<br>            9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0 /</p>
<p>   call <font color="#DF4442">MPI_INIT</font>(ierr)<br>   call <font color="#DF4442">MPI_COMM_RANK</font>(MPI_COMM_WORLD, rank, ierr)<br>   call <font color="#DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   blocklengths(0) = 4<br>   blocklengths(1) = 2<br>   displacements(0) = 5<br>   displacements(1) = 12</p>
<p>   <font color="#AAAAAA">! create indexed derived data type</font><br>   call <font color="#DF4442">MPI_TYPE_INDEXED</font>(2, blocklengths, displacements, MPI_REAL, &amp;<br>                         indextype, ierr)<br>   call <font color="#DF4442">MPI_TYPE_COMMIT</font>(indextype, ierr)</p>
<p>   if (rank .eq. 0) then<br>      <font color="#AAAAAA">! task 0 sends one element of indextype to all tasks</font><br>      do i=0, numtasks-1<br>      call <font color="#DF4442">MPI_SEND</font>(a, 1, indextype, i, tag, MPI_COMM_WORLD, ierr)<br>      end do<br>   endif</p>
<p>   <font color="#AAAAAA">! all tasks receive indextype data from task 0</font><br>   source = 0<br>   call <font color="#DF4442">MPI_RECV</font>(b, NELEMENTS, MPI_REAL, source, tag, MPI_COMM_WORLD, &amp;<br>                 stat, ierr)<br>   print *, ‘rank= ‘,rank,’ b= ‘,b</p>
<p>   <font color="#AAAAAA">! free datatype when done using it</font><br>   call <font color="#DF4442">MPI_TYPE_FREE</font>(indextype, ierr)<br>   call <font color="#DF4442">MPI_FINALIZE</font>(ierr)</p>
<p>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<p> Sample program output: </p>
 <pre>rank= 0  b= 6.0 7.0 8.0 9.0 13.0 14.0
rank= 1  b= 6.0 7.0 8.0 9.0 13.0 14.0
rank= 2  b= 6.0 7.0 8.0 9.0 13.0 14.0
rank= 3  b= 6.0 7.0 8.0 9.0 13.0 14.0
</pre>

<h3 id="示例-结构派生的数据类型"><a href="#示例-结构派生的数据类型" class="headerlink" title="示例:结构派生的数据类型"></a>示例:结构派生的数据类型</h3><p>创建表示粒子的数据类型，并将这些粒子的数组分发给所有进程。</p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Struct Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;
   #define NELEM 25

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, source=0, dest, tag=1, i;</p>
<p>   typedef struct {<br>     float x, y, z;<br>     float velocity;<br>     int  n, type;<br>     }          Particle;<br>   Particle     p[NELEM], particles[NELEM];<br>   <font color="#DF4442">MPI_Datatype particletype, oldtypes[2]</font>;   <font color="#AAAAAA">// required variables</font><br>   int          blockcounts[2];</p>
<p>   <font color="#AAAAAA">// MPI_Aint type used to be consistent with syntax of</font><br>   <font color="#AAAAAA">// MPI_Type_extent routine</font><br>   <font color="#DF4442">MPI_Aint    offsets[2], extent</font>;</p>
<p>   <font color="#DF4442">MPI_Status stat</font>;</p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);</p>
<p>   <font color="#AAAAAA">// setup description of the 4 MPI_FLOAT fields x, y, z, velocity</font><br>   offsets[0] = 0;<br>   oldtypes[0] = MPI_FLOAT;<br>   blockcounts[0] = 4;</p>
<p>   <font color="#AAAAAA">// setup description of the 2 MPI_INT fields n, type</font><br>   <font color="#AAAAAA">// need to first figure offset by getting size of MPI_FLOAT</font><br>   <font color="#DF4442">MPI_Type_extent</font>(MPI_FLOAT, &amp;extent);<br>   offsets[1] = 4 * extent;<br>   oldtypes[1] = MPI_INT;<br>   blockcounts[1] = 2;</p>
<p>   <font color="#AAAAAA">// define structured type and commit it</font><br>   <font color="#DF4442">MPI_Type_struct</font>(2, blockcounts, offsets, oldtypes, &amp;particletype);<br>   <font color="#DF4442">MPI_Type_commit</font>(&amp;particletype);</p>
<p>   <font color="#AAAAAA">// task 0 initializes the particle array and then sends it to each task</font><br>   if (rank == 0) {<br>     for (i=0; i&lt;NELEM; i++) {<br>        particles[i].x = i * 1.0;<br>        particles[i].y = i * -1.0;<br>        particles[i].z = i * 1.0;<br>        particles[i].velocity = 0.25;<br>        particles[i].n = i;<br>        particles[i].type = i % 2;<br>        }<br>     for (i=0; i&lt;numtasks; i++)<br>        <font color="#DF4442">MPI_Send</font>(particles, NELEM, particletype, i, tag, MPI_COMM_WORLD);<br>     }</p>
<p>   <font color="#AAAAAA">// all tasks receive particletype data</font><br>   <font color="#DF4442">MPI_Recv</font>(p, NELEM, particletype, source, tag, MPI_COMM_WORLD, &amp;stat);</p>
<p>   printf(“rank= %d   %3.2f %3.2f %3.2f %3.2f %d %d\n”, rank,p[3].x,<br>        p[3].y,p[3].z,p[3].velocity,p[3].n,p[3].type);</p>
<p>   <font color="#AAAAAA">// free datatype when done using it</font><br>   <font color="#DF4442">MPI_Type_free</font>(&amp;particletype);<br>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortan - Struct Derived Data Type Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program struct
   include <font color="#DF4442">'mpif.h'</font>

<p>   integer NELEM<br>   parameter(NELEM=25)<br>   integer numtasks, rank, source, dest, tag, i,  ierr<br>   integer <font color="#DF4442">stat(MPI_STATUS_SIZE)</font></p>
<p>   type Particle<br>   sequence<br>   real*4 x, y, z, velocity<br>   integer n, type<br>   end type Particle</p>
<p>   type (Particle) p(NELEM), particles(NELEM)<br>   integer <font color="#DF4442">particletype, oldtypes(0:1)</font>   <font color="#AAAAAA">! required variables</font><br>   integer blockcounts(0:1), offsets(0:1), extent<br>   tag = 1</p>
<p>   call <font color="#DF4442">MPI_INIT</font>(ierr)<br>   call <font color="#DF4442">MPI_COMM_RANK</font>(MPI_COMM_WORLD, rank, ierr)<br>   call <font color="#DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   <font color="#AAAAAA">! setup description of the 4 MPI_REAL fields x, y, z, velocity</font><br>   offsets(0) = 0<br>   oldtypes(0) = MPI_REAL<br>   blockcounts(0) = 4</p>
<p>   <font color="#AAAAAA">! setup description of the 2 MPI_INTEGER fields n, type</font><br>   <font color="#AAAAAA">! need to first figure offset by getting size of MPI_REAL</font><br>   call <font color="#DF4442">MPI_TYPE_EXTENT</font>(MPI_REAL, extent, ierr)<br>   offsets(1) = 4 * extent<br>   oldtypes(1) = MPI_INTEGER<br>   blockcounts(1) = 2</p>
<p>   <font color="#AAAAAA">! define structured type and commit it</font><br>   call <font color="#DF4442">MPI_TYPE_STRUCT</font>(2, blockcounts, offsets, oldtypes, &amp;<br>                        particletype, ierr)<br>   call <font color="#DF4442">MPI_TYPE_COMMIT</font>(particletype, ierr)</p>
<p>   <font color="#AAAAAA">! task 0 initializes the particle array and then sends it to each task</font><br>   if (rank .eq. 0) then<br>      do i=0, NELEM-1<br>      particles(i) = Particle ( 1.0<em>i, -1.0</em>i, 1.0*i, 0.25, i, mod(i,2) )<br>      end do</p>
<pre><code>do i=0, numtasks-1
call &lt;font color=&quot;#DF4442&quot;&gt;MPI_SEND&lt;/font&gt;(particles, NELEM, particletype, i, tag, &amp;amp;
              MPI_COMM_WORLD, ierr)
end do</code></pre><p>   endif</p>
<p>   <font color="#AAAAAA">! all tasks receive particletype data</font><br>   source = 0<br>   call <font color="#DF4442">MPI_RECV</font>(p, NELEM, particletype, source, tag, &amp;<br>                 MPI_COMM_WORLD, stat, ierr)</p>
<p>   print *, ‘rank= ‘,rank,’ p(3)= ‘,p(3)</p>
<p>   <font color="#AAAAAA">! free datatype when done using it</font><br>   call <font color="#DF4442">MPI_TYPE_FREE</font>(particletype, ierr)<br>   call <font color="#DF4442">MPI_FINALIZE</font>(ierr)<br>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<p> Sample program output: </p>
 <pre>rank= 0   3.00 -3.00 3.00 0.25 3 1
rank= 2   3.00 -3.00 3.00 0.25 3 1
rank= 1   3.00 -3.00 3.00 0.25 3 1
rank= 3   3.00 -3.00 3.00 0.25 3 1
</pre>

<h2 id="组和通信子管理例程"><a href="#组和通信子管理例程" class="headerlink" title="组和通信子管理例程"></a>组和通信子管理例程</h2><h3 id="Groups-vs-Communicators"><a href="#Groups-vs-Communicators" class="headerlink" title="Groups vs. Communicators:"></a>Groups vs. Communicators:</h3><ul>
<li>组是一组有序的进程集合。组中的每个进程都与一个惟一的整数rank相关联。rank值从0到N-1，其中N是组中的进程数。在MPI中，组在系统内存中表示为一个对象。程序员只能通过一个“句柄”来访问它。组总是与通信器对象关联。</li>
<li>通信器包含一组可以相互通信的进程。所有MPI消息必须指定一个通信器。从最简单的意义上说，通信器是一个额外的“标记”，必须包含在MPI调用中。像组一样，通信器在系统内存中表示为对象，程序员只能通过“句柄”访问它。例如，包含所有任务的通信器的句柄是MPI_COMM_WORLD。</li>
<li>从程序员的角度来看，一个组和一个通信者是一体的。组例程主要用于指定应该使用哪些进程来构造通信器。</li>
</ul>
<h3 id="组和通信器对象的主要用途"><a href="#组和通信器对象的主要用途" class="headerlink" title="组和通信器对象的主要用途"></a>组和通信器对象的主要用途</h3><ol>
<li>允许您根据功能将任务组织为任务组。</li>
<li>启用跨相关任务子集的集体通信操作。</li>
<li>为实现用户定义的虚拟拓扑提供基础</li>
<li>提供安全通讯</li>
</ol>
<h3 id="编程注意事项和限制-1"><a href="#编程注意事项和限制-1" class="headerlink" title="编程注意事项和限制"></a>编程注意事项和限制</h3><ul>
<li>组/通信子是动态的——它可以在程序执行期间创建和销毁</li>
<li>过程可以是在一个以上的组/通信子。他们在各组/通信子的rank是唯一的。</li>
<li>MPI提供了40多个与组、通信器和虚拟拓扑相关的例程。</li>
<li>Typical usage: <ol>
<li>使用MPI_COMM_group从MPI_COMM_WORLD中提取全局group的句柄</li>
<li>使用MPI_group_incl形成新组作为全局组的子集</li>
<li>使用MPI_Comm_Create为新组创建新的通信器</li>
<li>使用MPI_Comm_rank确定新通信器中的新rank</li>
<li>使用任何MPI消息传递例程进行通信</li>
<li>完成后，使用MPI_Comm_free和MPI_group_free释放新的通信和组(可选)</li>
</ol>
</li>
</ul>
<h3 id="Group-and-Communicator-Management-Routines"><a href="#Group-and-Communicator-Management-Routines" class="headerlink" title="Group and Communicator Management Routines"></a>Group and Communicator Management Routines</h3><p>为单独的集体通信交换创建两个不同的进程组。还需要创建新的通信器。</p>
<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Group and Communicator Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;
   #define NPROCS 8

<p>   main(int argc, char *argv[])  {<br>   int        rank, new_rank, sendbuf, recvbuf, numtasks,<br>              ranks1[4]={0,1,2,3}, ranks2[4]={4,5,6,7};<br>   <font color="DF4442">MPI_Group  orig_group, new_group</font>;   <font color="#AAAAAA">// required variables</font><br>   <font color="DF4442">MPI_Comm   new_comm</font>;   <font color="#AAAAAA">// required variable</font></p>
<p>   <font color="DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="DF4442">MPI_Comm_rank</font>(MPI_COMM_WORLD, &amp;rank);<br>   <font color="DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);</p>
<p>   if (numtasks != NPROCS) {<br>     printf(“Must specify MP_PROCS= %d. Terminating.\n”,NPROCS);<br>     <font color="DF4442">MPI_Finalize</font>();<br>     exit(0);<br>     }</p>
<p>   sendbuf = rank;</p>
<p>   <font color="#AAAAAA">// extract the original group handle</font><br>   <font color="DF4442">MPI_Comm_group</font>(MPI_COMM_WORLD, &amp;orig_group);</p>
<p>   <font color="#AAAAAA">//  divide tasks into two distinct groups based upon rank</font><br>   if (rank &lt; NPROCS/2) {<br>     <font color="DF4442">MPI_Group_incl</font>(orig_group, NPROCS/2, ranks1, &amp;new_group);<br>     }<br>   else {<br>     <font color="DF4442">MPI_Group_incl</font>(orig_group, NPROCS/2, ranks2, &amp;new_group);<br>     }</p>
<p>   <font color="#AAAAAA">// create new new communicator and then perform collective communications</font><br>   <font color="DF4442">MPI_Comm_create</font>(MPI_COMM_WORLD, new_group, &amp;new_comm);<br>   <font color="DF4442">MPI_Allreduce</font>(&amp;sendbuf, &amp;recvbuf, 1, MPI_INT, MPI_SUM, new_comm);</p>
<p>   <font color="#AAAAAA">// get rank in new group</font><br>   <font color="DF4442">MPI_Group_rank</font> (new_group, &amp;new_rank);<br>   printf(“rank= %d newrank= %d recvbuf= %d\n”,rank,new_rank,recvbuf);</p>
<p>   <font color="DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortran - Group and Communicator Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program group
   include <font color="DF4442">'mpif.h'</font>

<p>   integer NPROCS<br>   parameter(NPROCS=8)<br>   integer rank, new_rank, sendbuf, recvbuf, numtasks<br>   integer ranks1(4), ranks2(4), ierr<br>   integer <font color="DF4442">orig_group, new_group, new_comm</font>   <font color="#AAAAAA">! required variables</font><br>   data ranks1 /0, 1, 2, 3/, ranks2 /4, 5, 6, 7/</p>
<p>   call <font color="DF4442">MPI_INIT</font>(ierr)<br>   call <font color="DF4442">MPI_COMM_RANK</font>(MPI_COMM_WORLD, rank, ierr)<br>   call <font color="DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   if (numtasks .ne. NPROCS) then<br>     print *, ‘Must specify NPROCS= ‘,NPROCS,’ Terminating.’<br>     call <font color="DF4442">MPI_FINALIZE</font>(ierr)<br>     stop<br>   endif</p>
<p>   sendbuf = rank</p>
<p>   <font color="#AAAAAA">! extract the original group handle</font><br>   call <font color="DF4442">MPI_COMM_GROUP</font>(MPI_COMM_WORLD, orig_group, ierr)</p>
<p>   <font color="#AAAAAA">! divide tasks into two distinct groups based upon rank</font><br>   if (rank .lt. NPROCS/2) then<br>      call <font color="DF4442">MPI_GROUP_INCL</font>(orig_group, NPROCS/2, ranks1, new_group, ierr)<br>   else<br>      call <font color="DF4442">MPI_GROUP_INCL</font>(orig_group, NPROCS/2, ranks2, new_group, ierr)<br>   endif</p>
<p>   <font color="#AAAAAA">! create new new communicator and then perform collective communications</font><br>   call <font color="DF4442">MPI_COMM_CREATE</font>(MPI_COMM_WORLD, new_group, new_comm, ierr)<br>   call <font color="DF4442">MPI_ALLREDUCE</font>(sendbuf, recvbuf, 1, MPI_INTEGER, MPI_SUM, new_comm, ierr)</p>
<p>   <font color="#AAAAAA">! get rank in new group</font><br>   call <font color="DF4442">MPI_GROUP_RANK</font>(new_group, new_rank, ierr)<br>   print *, ‘rank= ‘,rank,’ newrank= ‘,new_rank,’ recvbuf= ‘, recvbuf</p>
<p>   call <font color="DF4442">MPI_FINALIZE</font>(ierr)<br>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<p> Sample program output: </p>
 <pre>rank= 7 newrank= 3 recvbuf= 22
rank= 0 newrank= 0 recvbuf= 6
rank= 1 newrank= 1 recvbuf= 6
rank= 2 newrank= 2 recvbuf= 6
rank= 6 newrank= 2 recvbuf= 22
rank= 3 newrank= 3 recvbuf= 6
rank= 4 newrank= 0 recvbuf= 22
rank= 5 newrank= 1 recvbuf= 22
</pre>

<h2 id="虚拟拓扑-Virtual-Topologies"><a href="#虚拟拓扑-Virtual-Topologies" class="headerlink" title="虚拟拓扑(Virtual Topologies)"></a>虚拟拓扑(Virtual Topologies)</h2><h3 id="What-Are-They"><a href="#What-Are-They" class="headerlink" title="What Are They?"></a>What Are They?</h3><ul>
<li>In terms of MPI, a virtual topology describes a mapping/ordering of MPI processes into a geometric “shape”. </li>
<li>MPI支持的两种主要拓扑类型是笛卡尔(网格)和图。</li>
<li>MPI拓扑是虚拟的——并行机的物理结构和进程拓扑之间可能没有关系。</li>
<li>虚拟拓扑构建在MPI通信器和组之上。</li>
<li>必须由应用程序开发人员“编程”。</li>
</ul>
<h3 id="Why-Use-Them"><a href="#Why-Use-Them" class="headerlink" title="Why Use Them?"></a>Why Use Them?</h3><ul>
<li>Convenience <ul>
<li>虚拟拓扑可能对具有特定通信模式(与MPI拓扑结构匹配的模式)的应用程序有用。</li>
<li>例如，对于需要对基于网格的数据进行4路最近邻通信的应用程序，笛卡尔拓扑可能很方便。</li>
</ul>
</li>
<li>Communication Efficiency <ul>
<li>一些硬件架构可能会对相继相隔很远的“节点”之间的通信进行惩罚。</li>
<li>特定的实现可以根据给定并行机的物理特性来优化进程映射。</li>
<li>进程到MPI虚拟拓扑的映射依赖于MPI实现，可能完全被忽略。</li>
</ul>
</li>
</ul>
<h3 id="虚拟拓扑的例程"><a href="#虚拟拓扑的例程" class="headerlink" title="虚拟拓扑的例程"></a>虚拟拓扑的例程</h3><p> Create a 4 x 4 Cartesian topology from 16 processors and have each process exchange its rank with four neighbors. </p>
 <table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
C Language - Cartesian Virtual Topology Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   #include <font color="#DF4442">"mpi.h"</font>
   #include &lt;stdio.h&gt;
   #define SIZE 16
   #define UP    0
   #define DOWN  1
   #define LEFT  2
   #define RIGHT 3

<p>   main(int argc, char *argv[])  {<br>   int numtasks, rank, source, dest, outbuf, i, tag=1,<br>      inbuf[4]={MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL,},<br>      nbrs[4], dims[2]={4,4},<br>      periods[2]={0,0}, reorder=0, coords[2];</p>
<p>   <font color="#DF4442">MPI_Request reqs[8]</font>;<br>   <font color="#DF4442">MPI_Status stats[8]</font>;<br>   <font color="#DF4442">MPI_Comm cartcomm</font>;   <font color="#AAAAAA">// required variable</font></p>
<p>   <font color="#DF4442">MPI_Init</font>(&amp;argc,&amp;argv);<br>   <font color="#DF4442">MPI_Comm_size</font>(MPI_COMM_WORLD, &amp;numtasks);</p>
<p>   if (numtasks == SIZE) {<br>      <font color="#AAAAAA">// create cartesian virtual topology, get rank, coordinates, neighbor ranks</font><br>      <font color="#DF4442">MPI_Cart_create</font>(MPI_COMM_WORLD, 2, dims, periods, reorder, &amp;cartcomm);<br>      <font color="#DF4442">MPI_Comm_rank</font>(cartcomm, &amp;rank);<br>      <font color="#DF4442">MPI_Cart_coords</font>(cartcomm, rank, 2, coords);<br>      <font color="#DF4442">MPI_Cart_shift</font>(cartcomm, 0, 1, &amp;nbrs[UP], &amp;nbrs[DOWN]);<br>      <font color="#DF4442">MPI_Cart_shift</font>(cartcomm, 1, 1, &amp;nbrs[LEFT], &amp;nbrs[RIGHT]);</p>
<pre><code>printf(&quot;rank= %d coords= %d %d  neighbors(u,d,l,r)= %d %d %d %d\n&quot;,
       rank,coords[0],coords[1],nbrs[UP],nbrs[DOWN],nbrs[LEFT],
       nbrs[RIGHT]);

outbuf = rank;

&lt;font color=&quot;#AAAAAA&quot;&gt;// exchange data (rank) with 4 neighbors&lt;/font&gt;
for (i=0; i&amp;lt;4; i++) {
   dest = nbrs[i];
   source = nbrs[i];
   &lt;font color=&quot;#DF4442&quot;&gt;MPI_Isend&lt;/font&gt;(&amp;amp;outbuf, 1, MPI_INT, dest, tag, 
             MPI_COMM_WORLD, &amp;amp;reqs[i]);
   &lt;font color=&quot;#DF4442&quot;&gt;MPI_Irecv&lt;/font&gt;(&amp;amp;inbuf[i], 1, MPI_INT, source, tag, 
             MPI_COMM_WORLD, &amp;amp;reqs[i+4]);
   }

&lt;font color=&quot;#DF4442&quot;&gt;MPI_Waitall&lt;/font&gt;(8, reqs, stats);

printf(&quot;rank= %d                  inbuf(u,d,l,r)= %d %d %d %d\n&quot;,
       rank,inbuf[UP],inbuf[DOWN],inbuf[LEFT],inbuf[RIGHT]);  }</code></pre><p>   else<br>      printf(“Must specify %d processors. Terminating.\n”,SIZE);</p>
<p>   <font color="#DF4442">MPI_Finalize</font>();<br>   }</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<table width="90%" cellspacing="0" cellpadding="15" border="1"><tbody><tr><td> <!---outer table--->
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>
<td colspan="2" width="30" bgcolor="FOF5FE" align="center"><img src="../images/page01.gif"></td>
<td bgcolor="FOF5FE"><b><br>&nbsp;&nbsp;&nbsp;&nbsp;
Fortran - Cartesian Virtual Topology Example
</b><p></p></td>

</tr><tr valign="top"><td colspan="3"><p></p></td>

</tr><tr valign="top">
<td width="30"><pre><font color="#AAAAAA"> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58</font></pre></td>

<td width="1" bgcolor="#7099cc"></td>

<td><pre>   program cartesian
   include <font color="#DF4442">'mpif.h'</font>

<p>   integer SIZE, UP, DOWN, LEFT, RIGHT<br>   parameter(SIZE=16)<br>   parameter(UP=1)<br>   parameter(DOWN=2)<br>   parameter(LEFT=3)<br>   parameter(RIGHT=4)<br>   integer numtasks, rank, source, dest, outbuf, i, tag, ierr, &amp;<br>           inbuf(4), nbrs(4), dims(2), coords(2), periods(2), reorder<br>   integer <font color="#DF4442">stats(MPI_STATUS_SIZE, 8), reqs(8)</font><br>   integer <font color="#DF4442">cartcomm</font>   <font color="#AAAAAA">! required variable</font><br>   data inbuf /MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL/, &amp;<br>        dims /4,4/, tag /1/, periods /0,0/, reorder /0/ </p>
<p>   call <font color="#DF4442">MPI_INIT</font>(ierr)<br>   call <font color="#DF4442">MPI_COMM_SIZE</font>(MPI_COMM_WORLD, numtasks, ierr)</p>
<p>   if (numtasks .eq. SIZE) then<br>      <font color="#AAAAAA">! create cartesian virtual topology, get rank, coordinates, neighbor ranks</font><br>      call <font color="#DF4442">MPI_CART_CREATE</font>(MPI_COMM_WORLD, 2, dims, periods, reorder, &amp;<br>                           cartcomm, ierr)<br>      call <font color="#DF4442">MPI_COMM_RANK</font>(cartcomm, rank, ierr)<br>      call <font color="#DF4442">MPI_CART_COORDS</font>(cartcomm, rank, 2, coords, ierr)<br>      call <font color="#DF4442">MPI_CART_SHIFT</font>(cartcomm, 0, 1, nbrs(UP), nbrs(DOWN), ierr)<br>      call <font color="#DF4442">MPI_CART_SHIFT</font>(cartcomm, 1, 1, nbrs(LEFT), nbrs(RIGHT), ierr)</p>
<pre><code>write(*,20) rank,coords(1),coords(2),nbrs(UP),nbrs(DOWN), &amp;amp;
            nbrs(LEFT),nbrs(RIGHT)

&lt;font color=&quot;#AAAAAA&quot;&gt;! exchange data (rank) with 4 neighbors&lt;/font&gt;
outbuf = rank
do i=1,4
   dest = nbrs(i)
   source = nbrs(i)
   call &lt;font color=&quot;#DF4442&quot;&gt;MPI_ISEND&lt;/font&gt;(outbuf, 1, MPI_INTEGER, dest, tag, &amp;amp;
                 MPI_COMM_WORLD, reqs(i), ierr)
   call &lt;font color=&quot;#DF4442&quot;&gt;MPI_IRECV&lt;/font&gt;(inbuf(i), 1, MPI_INTEGER, source, tag, &amp;amp;
                 MPI_COMM_WORLD, reqs(i+4), ierr)
enddo

call &lt;font color=&quot;#DF4442&quot;&gt;MPI_WAITALL&lt;/font&gt;(8, reqs, stats, ierr)

write(*,30) rank,inbuf</code></pre><p>   else<br>     print *, ‘Must specify’,SIZE,’ processors.  Terminating.’<br>   endif</p>
<p>   call <font color="#DF4442">MPI_FINALIZE</font>(ierr)</p>
<p>   20 format(‘rank= ‘,I3,’ coords= ‘,I2,I2, &amp;<br>             ‘ neighbors(u,d,l,r)= ‘,I3,I3,I3,I3 )<br>   30 format(‘rank= ‘,I3,’                 ‘, &amp;<br>             ‘ inbuf(u,d,l,r)= ‘,I3,I3,I3,I3 )</p>
<p>   end</p>
<p></pre></td></p>
</tr></tbody></table>
</td></tr></tbody></table>

<p> Sample program output: (partial) </p>
 <pre>rank=   0 coords=  0 0 neighbors(u,d,l,r)=  -1  4 -1  1
rank=   0                  inbuf(u,d,l,r)=  -1  4 -1  1
rank=   8 coords=  2 0 neighbors(u,d,l,r)=   4 12 -1  9
rank=   8                  inbuf(u,d,l,r)=   4 12 -1  9
rank=   1 coords=  0 1 neighbors(u,d,l,r)=  -1  5  0  2
rank=   1                  inbuf(u,d,l,r)=  -1  5  0  2
rank=  13 coords=  3 1 neighbors(u,d,l,r)=   9 -1 12 14
rank=  13                  inbuf(u,d,l,r)=   9 -1 12 14
...
...
rank=   3 coords=  0 3 neighbors(u,d,l,r)=  -1  7  2 -1
rank=   3                  inbuf(u,d,l,r)=  -1  7  2 -1
rank=  11 coords=  2 3 neighbors(u,d,l,r)=   7 15 10 -1
rank=  11                  inbuf(u,d,l,r)=   7 15 10 -1
rank=  10 coords=  2 2 neighbors(u,d,l,r)=   6 14  9 11
rank=  10                  inbuf(u,d,l,r)=   6 14  9 11
rank=   9 coords=  2 1 neighbors(u,d,l,r)=   5 13  8 10
rank=   9                  inbuf(u,d,l,r)=   5 13  8 10
</pre>

<h2 id="简要介绍一下MPI-2和MPI-3"><a href="#简要介绍一下MPI-2和MPI-3" class="headerlink" title="简要介绍一下MPI-2和MPI-3"></a>简要介绍一下MPI-2和MPI-3</h2><h3 id="MPI-2"><a href="#MPI-2" class="headerlink" title="MPI-2:"></a>MPI-2:</h3><ul>
<li>有意地，MPI-1规范没有解决几个“困难的”问题。出于权宜之计，这些问题在1998年被推迟到第二个规范，称为MPI-2。</li>
<li>MPI-2是对MPI-1的重大修订，增加了新的功能和修正。</li>
<li>MPI-2新功能的关键领域<ul>
<li><strong>动态进程</strong>——删除MPI静态进程模型的扩展。提供在作业启动后创建新进程的例程。</li>
<li><strong>One-Sided Communications</strong> - provides routines for one directional communications. Include shared memory operations (put/get) and remote accumulate operations. </li>
<li><strong>扩展的集合操作</strong>-允许应用集合操作的内部通信</li>
<li><strong>外部接口</strong>——定义允许开发人员在MPI之上构建的例程，比如调试器和分析器。</li>
<li><strong>其他语言绑定</strong>——描述c++绑定并讨论Fortran-90问题。</li>
<li><strong>Parallel I/O</strong> - describes MPI support for parallel I/O. </li>
</ul>
</li>
</ul>
<h3 id="MPI-3"><a href="#MPI-3" class="headerlink" title="MPI-3:"></a>MPI-3:</h3><ul>
<li>MPI-3标准于2012年采用，包含了对MPI-1和MPI-2功能的重要扩展，包括<ul>
<li><strong>非阻塞的集合操作</strong>——允许集合中的任务在没有阻塞的情况下执行操作，可能提供性能改进。</li>
<li><strong>新的单边通信操作</strong>-更好地处理不同的内存模型。</li>
<li><strong>邻域集合</strong>——扩展了分布式图和笛卡尔进程拓扑，增加了通信能力。</li>
<li><strong>Fortran</strong> 2008 Bindings - expanded from Fortran90 bindings </li>
<li><strong>MPIT Tool Interface</strong> - allows the MPI implementation to expose certain internal variables, counters, and other states to the user (most likely performance tools). </li>
<li><strong>Matched Probe</strong> - fixes an old bug in MPI-2 where one could not probe for messages in a multi-threaded environment. </li>
</ul>
</li>
</ul>
<h3 id="More-Information-on-MPI-2-and-MPI-3"><a href="#More-Information-on-MPI-2-and-MPI-3" class="headerlink" title="More Information on MPI-2 and MPI-3:"></a>More Information on MPI-2 and MPI-3:</h3><ul>
<li>  MPI Standard documents: <a href="http://www.mpi-forum.org/docs/" target="_blank" rel="noopener">http://www.mpi-forum.org/docs/</a> </li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/05/22/archlinux-NVIDIA-Bumblebee-CUDA-cudnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/22/archlinux-NVIDIA-Bumblebee-CUDA-cudnn/" itemprop="url">archlinux+NVIDIA+Bumblebee+CUDA+cudnn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-22T22:04:13+08:00">
                2020-05-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="NVIDIA"><a href="#NVIDIA" class="headerlink" title="NVIDIA"></a><a href="https://wiki.archlinux.org/index.php/NVIDIA_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#%E6%9C%80%E5%B0%8F%E9%85%8D%E7%BD%AE%E6%A8%A1%E5%BC%8F" target="_blank" rel="noopener">NVIDIA</a></h2><h3 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h3><p><code>pacman -S nvidia</code><br>或者<br><code>pacman -S nvidia-lts</code></p>
<h3 id="2-配置"><a href="#2-配置" class="headerlink" title="2. 配置"></a>2. 配置</h3><p>安装完驱动之后，您需要创建Xorg的配置文件。您可以运行一次测试来检验没有配置<br>文件Xorg能否正确运行。但是，您可能需要创建配置文件<code>/etc/X11/xorg.conf</code>来调<br>整Xorg运行时的一些变量。您可以用nvidia-xconfig配置工具来生成这些文件，也可<br>以手动创建。假如您是手动创建的话，它可以是一个最小的配置文件(也就是意味着<br>它仅仅把一些基础的选项传给Xorg服务器)，或者包含一些自定义的配置来绕开Xorg<br>的自动发现或者是预配置的选项。</p>
<h4 id="自动配置"><a href="#自动配置" class="headerlink" title="自动配置"></a>自动配置</h4><p>英伟达的软件包已经包含一个自动配置的工具来帮助您创建Xorg的配置文件(xorg.conf)您可以通过运行下面的命令来实现自动配置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-xconfig</span><br></pre></td></tr></table></figure>

<p>当Xorg的配置文件<code>xorg.conf</code>不存在时，这条命令会自动检测您的硬件，并创建文件<code>/etc/X11/xorg.conf</code>。假如配置文件已经存<br>在的话，它会进行一些编辑，以方便在Xorg运行时能成功载入英伟达的专有驱动。</p>
<h2 id="Bumblebee"><a href="#Bumblebee" class="headerlink" title="Bumblebee"></a><a href="https://wiki.archlinux.org/index.php/Bumblebee_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)" target="_blank" rel="noopener">Bumblebee</a></h2><p>安装 Bumblebee 之前，检查你的 BIOS 并尽可能激活 Optimus (老式电脑称之为”可切换显卡”，<br>BIOS有可能没有提供此项设置)。如果 “Optimus” 和 “switchable” 都没有在BIOS里，就保证<br>两种GPU都已启用并且集成显卡是主要显示设备。显示应该连接在主板上的集成显卡，而不是<br>独立显卡。如果集成显卡之前被禁用而安装了独立显卡的驱动，那就删除 <code>/etc/X11/xorg.conf</code><br>或者有关独立显卡的 <code>/etc/X11/xorg.conf.d</code> 中的文件。</p>
<h3 id="1-安装-1"><a href="#1-安装-1" class="headerlink" title="1. 安装"></a>1. 安装</h3><ul>
<li><a href="https://www.archlinux.org/packages/?name=bumblebee" target="_blank" rel="noopener">bumblebee</a> - 提供守护进程以及程序的主要安装包。</li>
<li><a href="https://www.archlinux.org/packages/?name=mesa" target="_blank" rel="noopener">mesa </a>- 开源的 OpenGL 标准实现。</li>
<li>对于合适的NVIDIA驱动，参看<a href="https://wiki.archlinux.org/index.php/NVIDIA_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#.E5.AE.89.E8.A3.85" target="_blank" rel="noopener">NVIDIA</a>安装 。</li>
<li><a href="https://www.archlinux.org/packages/?name=xf86-video-intel" target="_blank" rel="noopener">xf86-video-intel</a>- Intel 驱动（可选,用来做显示，nvidia只用来做计算）。</li>
</ul>
<h2 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a><a href="https://wiki.archlinux.org/index.php/GPGPU#CUDA" target="_blank" rel="noopener">CUDA</a></h2><h2 id="cudnn"><a href="#cudnn" class="headerlink" title="cudnn"></a><a href="https://security.archlinux.org/package/cudnn" target="_blank" rel="noopener">cudnn</a></h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/05/13/Ubuntu%E5%BC%80%E5%90%AFbbr/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/13/Ubuntu%E5%BC%80%E5%90%AFbbr/" itemprop="url">Ubuntu开启bbr</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-13T08:21:42+08:00">
                2020-05-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>当前场景为Ubuntu 2020.04LTS ,内核5.4，只需要开启配置即可</p>
<h2 id="1-修改系统变量"><a href="#1-修改系统变量" class="headerlink" title="1. 修改系统变量"></a>1. 修改系统变量</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># echo "net.core.default_qdisc=fq" &gt;&gt; /etc/sysctl.conf</span></span><br><span class="line"><span class="comment"># echo "net.ipv4.tcp_congestion_control=bbr" &gt;&gt; /etc/sysctl.conf</span></span><br></pre></td></tr></table></figure>

<h2 id="保存生效，配置内核"><a href="#保存生效，配置内核" class="headerlink" title="保存生效，配置内核"></a>保存生效，配置内核</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sysctl   -p</span></span><br></pre></td></tr></table></figure>

<p>显示如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.core.default_qdisc = fq</span><br><span class="line">net.ipv4.tcp_congestion_control = bbr</span><br></pre></td></tr></table></figure>

<h2 id="3、-查看内核是否已开启BBR"><a href="#3、-查看内核是否已开启BBR" class="headerlink" title="3、  查看内核是否已开启BBR"></a>3、  查看内核是否已开启BBR</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sysctl net.ipv4.tcp_available_congestion_control</span></span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_available_congestion_control = reno cubic bbr</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sysctl net.ipv4.tcp_congestion_control</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_congestion_control = bbr</span><br></pre></td></tr></table></figure>

<h2 id="4、-验证BBR是否已经启动"><a href="#4、-验证BBR是否已经启动" class="headerlink" title="4、 验证BBR是否已经启动"></a>4、 验证BBR是否已经启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># lsmod | grep bbr</span><br></pre></td></tr></table></figure>

<p>结果如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcp_bbr                20480  1</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/05/09/%E7%BD%91%E7%BB%9C%E6%8E%92%E6%9F%A5%E5%B7%A5%E5%85%B7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/09/%E7%BD%91%E7%BB%9C%E6%8E%92%E6%9F%A5%E5%B7%A5%E5%85%B7/" itemprop="url">网络排查工具</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-09T08:49:49+08:00">
                2020-05-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="mtr"><a href="#mtr" class="headerlink" title="mtr"></a>mtr</h2><p>查看本机到<code>baidu.com</code>的路由以及链接情况直接运行如下命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtr baidu.com</span><br></pre></td></tr></table></figure>

<h2 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h2><p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。<br><a href="https://www.cnblogs.com/peida/archive/2013/03/07/2947326.html" target="_blank" rel="noopener">每天一个linux命令（55）：traceroute命令</a></p>
<p>使用方法</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">traceroute www.baidu.com</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/05/06/v2ray-WS-TLS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/06/v2ray-WS-TLS/" itemprop="url">v2ray+WS+TLS</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-06T16:41:48+08:00">
                2020-05-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="1-1-服务端脚本安装"><a href="#1-1-服务端脚本安装" class="headerlink" title="1.1 服务端脚本安装"></a>1.1 服务端脚本安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://install.direct/go.sh &amp;&amp; bash go.sh</span><br></pre></td></tr></table></figure>
<h3 id="1-2-安装Nginx"><a href="#1-2-安装Nginx" class="headerlink" title="1.2 安装Nginx"></a>1.2 安装Nginx</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install nginx</span><br></pre></td></tr></table></figure>
<h2 id="注册域名"><a href="#注册域名" class="headerlink" title="注册域名"></a>注册域名</h2><p><a href="https://sg.godaddy.com/" target="_blank" rel="noopener">https://sg.godaddy.com/</a></p>
<h2 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h2><p><a href="https://www.cloudflare.com/" target="_blank" rel="noopener">https://www.cloudflare.com/</a></p>
<h3 id="3-1-cloudflare托管域名"><a href="#3-1-cloudflare托管域名" class="headerlink" title="3.1 cloudflare托管域名"></a>3.1 cloudflare托管域名</h3><h3 id="3-2-在cloudflare下载TLS证书"><a href="#3-2-在cloudflare下载TLS证书" class="headerlink" title="3.2 在cloudflare下载TLS证书"></a>3.2 在cloudflare下载TLS证书</h3><h2 id="WebSocket-TLS-Web"><a href="#WebSocket-TLS-Web" class="headerlink" title="WebSocket+TLS+Web"></a>WebSocket+TLS+Web</h2><h3 id="2-1-WebSocket-TLS-Web"><a href="#2-1-WebSocket-TLS-Web" class="headerlink" title="2.1 WebSocket+TLS+Web"></a>2.1 WebSocket+TLS+Web</h3><p>服务端配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"log"</span>: &#123;</span><br><span class="line">    <span class="string">"loglevel"</span>: <span class="string">"warning"</span>,</span><br><span class="line">    <span class="string">"access"</span>: <span class="string">"/dev/null"</span>,</span><br><span class="line">    <span class="string">"error"</span>: <span class="string">"/dev/null"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"inbounds"</span>: [&#123;</span><br><span class="line">    <span class="string">"listen"</span>:<span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="string">"port"</span>: 10000,</span><br><span class="line">    <span class="string">"protocol"</span>: <span class="string">"vmess"</span>,</span><br><span class="line">    <span class="string">"settings"</span>: &#123;</span><br><span class="line">      <span class="string">"clients"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"id"</span>: <span class="string">"XXXX"</span>,</span><br><span class="line">          <span class="string">"level"</span>: 1,</span><br><span class="line">          <span class="string">"alterId"</span>: 64</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"streamSettings"</span>:&#123;</span><br><span class="line">      <span class="string">"network"</span>:<span class="string">"ws"</span>,</span><br><span class="line">      <span class="string">"wsSettings"</span>:&#123;</span><br><span class="line">        <span class="string">"path"</span>: <span class="string">"/bannedbook"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;],</span><br><span class="line">  <span class="string">"outbounds"</span>: [&#123;</span><br><span class="line">    <span class="string">"protocol"</span>: <span class="string">"freedom"</span>,</span><br><span class="line">    <span class="string">"settings"</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">"tag"</span>: <span class="string">"allowed"</span></span><br><span class="line">  &#125;,&#123;</span><br><span class="line">    <span class="string">"protocol"</span>: <span class="string">"blackhole"</span>,</span><br><span class="line">    <span class="string">"settings"</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">"tag"</span>: <span class="string">"blocked"</span></span><br><span class="line">  &#125;],</span><br><span class="line">  <span class="string">"routing"</span>: &#123;</span><br><span class="line">    <span class="string">"rules"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"field"</span>,</span><br><span class="line">        <span class="string">"ip"</span>: [<span class="string">"geoip:private"</span>],</span><br><span class="line">        <span class="string">"outboundTag"</span>: <span class="string">"blocked"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"inbounds"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"port"</span>: 1080,</span><br><span class="line">      <span class="string">"listen"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">      <span class="string">"protocol"</span>: <span class="string">"socks"</span>,</span><br><span class="line">      <span class="string">"sniffing"</span>: &#123;</span><br><span class="line">        <span class="string">"enabled"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"destOverride"</span>: [<span class="string">"http"</span>, <span class="string">"tls"</span>]</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"settings"</span>: &#123;</span><br><span class="line">        <span class="string">"auth"</span>: <span class="string">"noauth"</span>,</span><br><span class="line">        <span class="string">"udp"</span>: <span class="literal">false</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"outbounds"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"protocol"</span>: <span class="string">"vmess"</span>,</span><br><span class="line">      <span class="string">"settings"</span>: &#123;</span><br><span class="line">        <span class="string">"vnext"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"address"</span>: <span class="string">"mydomain.com"</span>,</span><br><span class="line">            <span class="string">"port"</span>: 443,</span><br><span class="line">            <span class="string">"users"</span>: [</span><br><span class="line">              &#123;</span><br><span class="line">                <span class="string">"id"</span>: <span class="string">"XXXX"</span>,</span><br><span class="line">                <span class="string">"alterId"</span>: 64</span><br><span class="line">              &#125;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"streamSettings"</span>: &#123;</span><br><span class="line">        <span class="string">"network"</span>: <span class="string">"ws"</span>,</span><br><span class="line">        <span class="string">"security"</span>: <span class="string">"tls"</span>,</span><br><span class="line">        <span class="string">"wsSettings"</span>: &#123;</span><br><span class="line">          <span class="string">"path"</span>: <span class="string">"/bannedbook"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Nginx配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">user www-data;</span><br><span class="line">worker_processes auto;</span><br><span class="line">pid /run/nginx.pid;</span><br><span class="line">include /etc/nginx/modules-enabled/*.conf;</span><br><span class="line">worker_rlimit_nofile  655350;</span><br><span class="line">events &#123;</span><br><span class="line">	use epoll;</span><br><span class="line">	worker_connections 65536;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">	sendfile on;</span><br><span class="line">	tcp_nopush on;</span><br><span class="line">	tcp_nodelay on;</span><br><span class="line">	keepalive_timeout 65;</span><br><span class="line">	types_hash_max_size 2048;</span><br><span class="line">	include /etc/nginx/mime.types;</span><br><span class="line">	default_type application/octet-stream;</span><br><span class="line">	access_log /var/<span class="built_in">log</span>/nginx-access.log;</span><br><span class="line">	error_log /var/<span class="built_in">log</span>/nginx-error.log;</span><br><span class="line"></span><br><span class="line">	gzip on;</span><br><span class="line">  <span class="comment">#----------------WS+SSL----------------------#</span></span><br><span class="line">	server &#123;</span><br><span class="line">		listen  443 ssl;</span><br><span class="line">		ssl on;</span><br><span class="line">		ssl_certificate       /etc/v2ray/v2ray.crt;</span><br><span class="line">		ssl_certificate_key   /etc/v2ray/v2ray.key;</span><br><span class="line">		ssl_protocols         TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">		ssl_ciphers           HIGH:!aNULL:!MD5;</span><br><span class="line">		server_name           mydomain.com;</span><br><span class="line">        	location /bannedbook &#123;</span><br><span class="line">        		proxy_redirect off;</span><br><span class="line">        		proxy_pass http://127.0.0.1:10000;</span><br><span class="line">        		proxy_http_version 1.1;</span><br><span class="line">        		proxy_set_header Upgrade <span class="variable">$http_upgrade</span>;</span><br><span class="line">        		proxy_set_header Connection <span class="string">"upgrade"</span>;</span><br><span class="line">        		proxy_set_header Host <span class="variable">$http_host</span>;</span><br><span class="line"></span><br><span class="line">        		<span class="comment"># Show realip in v2ray access.log</span></span><br><span class="line">        		proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        		proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        	&#125;</span><br><span class="line">	&#125;</span><br><span class="line">  <span class="comment">#----------------WS--------------------------#</span></span><br><span class="line">	server &#123;</span><br><span class="line">		listen 80 default_server;</span><br><span class="line">		listen [::]:80 default_server;</span><br><span class="line">		root /var/www/html;</span><br><span class="line">		index index.html index.htm index.nginx-debian.html;</span><br><span class="line">		server_name _;</span><br><span class="line"></span><br><span class="line">		location / &#123;</span><br><span class="line">			try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ =404;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">    		location /bannedbook &#123; </span><br><span class="line">	    		proxy_redirect off;</span><br><span class="line">	    		proxy_pass http://127.0.0.1:10000; </span><br><span class="line">	    		proxy_http_version 1.1;</span><br><span class="line">	    		proxy_set_header Upgrade <span class="variable">$http_upgrade</span>;</span><br><span class="line">	    		proxy_set_header Connection <span class="string">"upgrade"</span>;</span><br><span class="line">	    		proxy_set_header Host <span class="variable">$http_host</span>;</span><br><span class="line">	</span><br><span class="line">	    		proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">	    		proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;	</span><br><span class="line">    		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/04/18/Tmux%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/18/Tmux%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" itemprop="url">Tmux使用教程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-18T11:19:44+08:00">
                2020-04-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Tmux-使用教程"><a href="#Tmux-使用教程" class="headerlink" title="Tmux 使用教程"></a><a href="https://www.ruanyifeng.com/blog/2019/10/tmux.html" target="_blank" rel="noopener">Tmux 使用教程</a></h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://levizebulon.github.io/2020/04/18/docker-spark-jupyternotebook/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linuzb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linuzb's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/18/docker-spark-jupyternotebook/" itemprop="url">docker+spark+jupyternotebook</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-18T10:30:55+08:00">
                2020-04-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><p><a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener">Install Docker Engine</a></p>
<h3 id="Install-Docker-Engine-on-Ubuntu"><a href="#Install-Docker-Engine-on-Ubuntu" class="headerlink" title="Install Docker Engine on Ubuntu"></a><a href="https://docs.docker.com/engine/install/ubuntu/" target="_blank" rel="noopener">Install Docker Engine on Ubuntu</a></h3><p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/" target="_blank" rel="noopener">清华Docker Community Edition 镜像使用帮助</a><br><a href="http://mirrors.ustc.edu.cn/help/docker-ce.html" target="_blank" rel="noopener">中科大Docker CE 源使用帮助</a><br><a href="http://mirrors.ustc.edu.cn/help/dockerhub.html" target="_blank" rel="noopener">中科大Docker Hub 源使用帮助</a><br><a href="https://yeasy.gitbooks.io/docker_practice/content/install/mirror.html" target="_blank" rel="noopener">docker镜像加速器</a></p>
<h2 id="安装jupyter-all-spark-notebook"><a href="#安装jupyter-all-spark-notebook" class="headerlink" title="安装jupyter/all-spark-notebook"></a>安装<a href="https://hub.docker.com/r/jupyter/all-spark-notebook/" target="_blank" rel="noopener">jupyter/all-spark-notebook</a></h2><p>使用方法：Jupyter Notebook Python, Scala, R, Spark, Mesos Stack<a href="https://github.com/Paperspace/jupyter-docker-stacks/tree/master/all-spark-notebook" target="_blank" rel="noopener">README</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">&lt;i class&#x3D;&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Linuzb</p>
              <p class="site-description motion-element" itemprop="description">记录学习过程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Linuzb</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
